{
    "text": " Check out this new state of the art model. We should push this to production. Think again. Do you understand why we wouldn't push a model that we read about in archive to production? Because you guys aren't comfortable with change. I don't know. Do you have any idea how much work it takes to build, train, validate, and deploy a model into our pipelines? I could do that in a couple hours. A model created by academics can take weeks for us to re-engineer and get working within our production pipelines. The other thing is the accuracy gains you're seeing, we don't know if that's gonna translate over to the problems we're trying to solve. And even if it doesn't prove accuracy, one or two percent accuracy isn't that big a deal for a lot of the applications that are often not worth upgrading just for that. So if you don't read archive all day, how do you improve your models? There are a lot of things we do. Tell them about your Kaggle work. I just finished competing in the auto competition on Kaggle and the third-place team used a rules-based approach that be thousands of people. It just goes to show you that understanding and knowing the data, you can build a rules-based approach that builds a machine learning model. Remember Tom, that PhD? Ugh, he spent weeks building a few-shot learning approach because he said he didn't have enough data, didn't get anywhere. We handed the project off to Sarah. She worked with a business, took a little bit of a free time, labeled some data, and she was able to quickly build a very effective model by just taking the time to label data. You data scientist. As the person who has to put these things in a production, I much prefer a simpler model. They're much easier to understand when I'm trying to troubleshoot them. They take a lot less compute. If you look at our data quality pipelines that we have, they're all using very simple bag of words models. I know you guys have those fancy transformer models, but those things take way too much compute, way too much resources. If we can do it with a simple model, that's what we're gonna choose. That makes a lot of sense. I should probably brush up on pass meetings where we talked about using tools like CleanLab as well as doing error analysis with our models. I just saw this data center AI course. All the videos are free. You might want to use it to brush up.",
    "segments": [
        {
            "id": 0,
            "seek": 0,
            "start": 0.0,
            "end": 1.8,
            "text": " Check out this new state of the art model.",
            "tokens": [
                50364,
                6881,
                484,
                341,
                777,
                1785,
                295,
                264,
                1523,
                2316,
                13,
                50454
            ],
            "temperature": 0.0,
            "avg_logprob": -0.18425026950457238,
            "compression_ratio": 1.716923076923077,
            "no_speech_prob": 0.023725001141428947
        },
        {
            "id": 1,
            "seek": 0,
            "start": 1.8,
            "end": 3.2800000000000002,
            "text": " We should push this to production.",
            "tokens": [
                50454,
                492,
                820,
                2944,
                341,
                281,
                4265,
                13,
                50528
            ],
            "temperature": 0.0,
            "avg_logprob": -0.18425026950457238,
            "compression_ratio": 1.716923076923077,
            "no_speech_prob": 0.023725001141428947
        },
        {
            "id": 2,
            "seek": 0,
            "start": 3.2800000000000002,
            "end": 4.12,
            "text": " Think again.",
            "tokens": [
                50528,
                6557,
                797,
                13,
                50570
            ],
            "temperature": 0.0,
            "avg_logprob": -0.18425026950457238,
            "compression_ratio": 1.716923076923077,
            "no_speech_prob": 0.023725001141428947
        },
        {
            "id": 3,
            "seek": 0,
            "start": 4.12,
            "end": 5.88,
            "text": " Do you understand why we wouldn't push a model",
            "tokens": [
                50570,
                1144,
                291,
                1223,
                983,
                321,
                2759,
                380,
                2944,
                257,
                2316,
                50658
            ],
            "temperature": 0.0,
            "avg_logprob": -0.18425026950457238,
            "compression_ratio": 1.716923076923077,
            "no_speech_prob": 0.023725001141428947
        },
        {
            "id": 4,
            "seek": 0,
            "start": 5.88,
            "end": 7.68,
            "text": " that we read about in archive to production?",
            "tokens": [
                50658,
                300,
                321,
                1401,
                466,
                294,
                23507,
                281,
                4265,
                30,
                50748
            ],
            "temperature": 0.0,
            "avg_logprob": -0.18425026950457238,
            "compression_ratio": 1.716923076923077,
            "no_speech_prob": 0.023725001141428947
        },
        {
            "id": 5,
            "seek": 0,
            "start": 7.68,
            "end": 9.52,
            "text": " Because you guys aren't comfortable with change.",
            "tokens": [
                50748,
                1436,
                291,
                1074,
                3212,
                380,
                4619,
                365,
                1319,
                13,
                50840
            ],
            "temperature": 0.0,
            "avg_logprob": -0.18425026950457238,
            "compression_ratio": 1.716923076923077,
            "no_speech_prob": 0.023725001141428947
        },
        {
            "id": 6,
            "seek": 0,
            "start": 9.52,
            "end": 10.36,
            "text": " I don't know.",
            "tokens": [
                50840,
                286,
                500,
                380,
                458,
                13,
                50882
            ],
            "temperature": 0.0,
            "avg_logprob": -0.18425026950457238,
            "compression_ratio": 1.716923076923077,
            "no_speech_prob": 0.023725001141428947
        },
        {
            "id": 7,
            "seek": 0,
            "start": 10.36,
            "end": 11.96,
            "text": " Do you have any idea how much work it takes",
            "tokens": [
                50882,
                1144,
                291,
                362,
                604,
                1558,
                577,
                709,
                589,
                309,
                2516,
                50962
            ],
            "temperature": 0.0,
            "avg_logprob": -0.18425026950457238,
            "compression_ratio": 1.716923076923077,
            "no_speech_prob": 0.023725001141428947
        },
        {
            "id": 8,
            "seek": 0,
            "start": 11.96,
            "end": 15.56,
            "text": " to build, train, validate, and deploy a model",
            "tokens": [
                50962,
                281,
                1322,
                11,
                3847,
                11,
                29562,
                11,
                293,
                7274,
                257,
                2316,
                51142
            ],
            "temperature": 0.0,
            "avg_logprob": -0.18425026950457238,
            "compression_ratio": 1.716923076923077,
            "no_speech_prob": 0.023725001141428947
        },
        {
            "id": 9,
            "seek": 0,
            "start": 15.56,
            "end": 16.68,
            "text": " into our pipelines?",
            "tokens": [
                51142,
                666,
                527,
                40168,
                30,
                51198
            ],
            "temperature": 0.0,
            "avg_logprob": -0.18425026950457238,
            "compression_ratio": 1.716923076923077,
            "no_speech_prob": 0.023725001141428947
        },
        {
            "id": 10,
            "seek": 0,
            "start": 16.68,
            "end": 18.52,
            "text": " I could do that in a couple hours.",
            "tokens": [
                51198,
                286,
                727,
                360,
                300,
                294,
                257,
                1916,
                2496,
                13,
                51290
            ],
            "temperature": 0.0,
            "avg_logprob": -0.18425026950457238,
            "compression_ratio": 1.716923076923077,
            "no_speech_prob": 0.023725001141428947
        },
        {
            "id": 11,
            "seek": 0,
            "start": 19.52,
            "end": 22.68,
            "text": " A model created by academics can take weeks for us",
            "tokens": [
                51340,
                316,
                2316,
                2942,
                538,
                25695,
                393,
                747,
                3259,
                337,
                505,
                51498
            ],
            "temperature": 0.0,
            "avg_logprob": -0.18425026950457238,
            "compression_ratio": 1.716923076923077,
            "no_speech_prob": 0.023725001141428947
        },
        {
            "id": 12,
            "seek": 0,
            "start": 22.68,
            "end": 25.76,
            "text": " to re-engineer and get working within our production pipelines.",
            "tokens": [
                51498,
                281,
                319,
                12,
                25609,
                260,
                293,
                483,
                1364,
                1951,
                527,
                4265,
                40168,
                13,
                51652
            ],
            "temperature": 0.0,
            "avg_logprob": -0.18425026950457238,
            "compression_ratio": 1.716923076923077,
            "no_speech_prob": 0.023725001141428947
        },
        {
            "id": 13,
            "seek": 0,
            "start": 25.76,
            "end": 28.28,
            "text": " The other thing is the accuracy gains you're seeing,",
            "tokens": [
                51652,
                440,
                661,
                551,
                307,
                264,
                14170,
                16823,
                291,
                434,
                2577,
                11,
                51778
            ],
            "temperature": 0.0,
            "avg_logprob": -0.18425026950457238,
            "compression_ratio": 1.716923076923077,
            "no_speech_prob": 0.023725001141428947
        },
        {
            "id": 14,
            "seek": 2828,
            "start": 28.28,
            "end": 29.880000000000003,
            "text": " we don't know if that's gonna translate over",
            "tokens": [
                50364,
                321,
                500,
                380,
                458,
                498,
                300,
                311,
                799,
                13799,
                670,
                50444
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11170793276781227,
            "compression_ratio": 1.7759103641456582,
            "no_speech_prob": 0.00046588756958954036
        },
        {
            "id": 15,
            "seek": 2828,
            "start": 29.880000000000003,
            "end": 31.400000000000002,
            "text": " to the problems we're trying to solve.",
            "tokens": [
                50444,
                281,
                264,
                2740,
                321,
                434,
                1382,
                281,
                5039,
                13,
                50520
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11170793276781227,
            "compression_ratio": 1.7759103641456582,
            "no_speech_prob": 0.00046588756958954036
        },
        {
            "id": 16,
            "seek": 2828,
            "start": 31.400000000000002,
            "end": 33.92,
            "text": " And even if it doesn't prove accuracy,",
            "tokens": [
                50520,
                400,
                754,
                498,
                309,
                1177,
                380,
                7081,
                14170,
                11,
                50646
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11170793276781227,
            "compression_ratio": 1.7759103641456582,
            "no_speech_prob": 0.00046588756958954036
        },
        {
            "id": 17,
            "seek": 2828,
            "start": 33.92,
            "end": 36.32,
            "text": " one or two percent accuracy isn't that big a deal",
            "tokens": [
                50646,
                472,
                420,
                732,
                3043,
                14170,
                1943,
                380,
                300,
                955,
                257,
                2028,
                50766
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11170793276781227,
            "compression_ratio": 1.7759103641456582,
            "no_speech_prob": 0.00046588756958954036
        },
        {
            "id": 18,
            "seek": 2828,
            "start": 36.32,
            "end": 37.480000000000004,
            "text": " for a lot of the applications",
            "tokens": [
                50766,
                337,
                257,
                688,
                295,
                264,
                5821,
                50824
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11170793276781227,
            "compression_ratio": 1.7759103641456582,
            "no_speech_prob": 0.00046588756958954036
        },
        {
            "id": 19,
            "seek": 2828,
            "start": 37.480000000000004,
            "end": 39.760000000000005,
            "text": " that are often not worth upgrading just for that.",
            "tokens": [
                50824,
                300,
                366,
                2049,
                406,
                3163,
                36249,
                445,
                337,
                300,
                13,
                50938
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11170793276781227,
            "compression_ratio": 1.7759103641456582,
            "no_speech_prob": 0.00046588756958954036
        },
        {
            "id": 20,
            "seek": 2828,
            "start": 39.760000000000005,
            "end": 41.56,
            "text": " So if you don't read archive all day,",
            "tokens": [
                50938,
                407,
                498,
                291,
                500,
                380,
                1401,
                23507,
                439,
                786,
                11,
                51028
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11170793276781227,
            "compression_ratio": 1.7759103641456582,
            "no_speech_prob": 0.00046588756958954036
        },
        {
            "id": 21,
            "seek": 2828,
            "start": 41.56,
            "end": 42.88,
            "text": " how do you improve your models?",
            "tokens": [
                51028,
                577,
                360,
                291,
                3470,
                428,
                5245,
                30,
                51094
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11170793276781227,
            "compression_ratio": 1.7759103641456582,
            "no_speech_prob": 0.00046588756958954036
        },
        {
            "id": 22,
            "seek": 2828,
            "start": 42.88,
            "end": 44.24,
            "text": " There are a lot of things we do.",
            "tokens": [
                51094,
                821,
                366,
                257,
                688,
                295,
                721,
                321,
                360,
                13,
                51162
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11170793276781227,
            "compression_ratio": 1.7759103641456582,
            "no_speech_prob": 0.00046588756958954036
        },
        {
            "id": 23,
            "seek": 2828,
            "start": 44.24,
            "end": 45.6,
            "text": " Tell them about your Kaggle work.",
            "tokens": [
                51162,
                5115,
                552,
                466,
                428,
                48751,
                22631,
                589,
                13,
                51230
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11170793276781227,
            "compression_ratio": 1.7759103641456582,
            "no_speech_prob": 0.00046588756958954036
        },
        {
            "id": 24,
            "seek": 2828,
            "start": 45.6,
            "end": 48.36,
            "text": " I just finished competing in the auto competition on Kaggle",
            "tokens": [
                51230,
                286,
                445,
                4335,
                15439,
                294,
                264,
                8399,
                6211,
                322,
                48751,
                22631,
                51368
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11170793276781227,
            "compression_ratio": 1.7759103641456582,
            "no_speech_prob": 0.00046588756958954036
        },
        {
            "id": 25,
            "seek": 2828,
            "start": 48.36,
            "end": 51.28,
            "text": " and the third-place team used a rules-based approach",
            "tokens": [
                51368,
                293,
                264,
                2636,
                12,
                6742,
                1469,
                1143,
                257,
                4474,
                12,
                6032,
                3109,
                51514
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11170793276781227,
            "compression_ratio": 1.7759103641456582,
            "no_speech_prob": 0.00046588756958954036
        },
        {
            "id": 26,
            "seek": 2828,
            "start": 51.28,
            "end": 52.760000000000005,
            "text": " that be thousands of people.",
            "tokens": [
                51514,
                300,
                312,
                5383,
                295,
                561,
                13,
                51588
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11170793276781227,
            "compression_ratio": 1.7759103641456582,
            "no_speech_prob": 0.00046588756958954036
        },
        {
            "id": 27,
            "seek": 2828,
            "start": 52.760000000000005,
            "end": 54.92,
            "text": " It just goes to show you that understanding and knowing",
            "tokens": [
                51588,
                467,
                445,
                1709,
                281,
                855,
                291,
                300,
                3701,
                293,
                5276,
                51696
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11170793276781227,
            "compression_ratio": 1.7759103641456582,
            "no_speech_prob": 0.00046588756958954036
        },
        {
            "id": 28,
            "seek": 2828,
            "start": 54.92,
            "end": 57.24,
            "text": " the data, you can build a rules-based approach",
            "tokens": [
                51696,
                264,
                1412,
                11,
                291,
                393,
                1322,
                257,
                4474,
                12,
                6032,
                3109,
                51812
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11170793276781227,
            "compression_ratio": 1.7759103641456582,
            "no_speech_prob": 0.00046588756958954036
        },
        {
            "id": 29,
            "seek": 5724,
            "start": 57.24,
            "end": 58.92,
            "text": " that builds a machine learning model.",
            "tokens": [
                50364,
                300,
                15182,
                257,
                3479,
                2539,
                2316,
                13,
                50448
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1487676529657273,
            "compression_ratio": 1.6101190476190477,
            "no_speech_prob": 0.0005119660636410117
        },
        {
            "id": 30,
            "seek": 5724,
            "start": 58.92,
            "end": 60.440000000000005,
            "text": " Remember Tom, that PhD?",
            "tokens": [
                50448,
                5459,
                5041,
                11,
                300,
                14476,
                30,
                50524
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1487676529657273,
            "compression_ratio": 1.6101190476190477,
            "no_speech_prob": 0.0005119660636410117
        },
        {
            "id": 31,
            "seek": 5724,
            "start": 60.440000000000005,
            "end": 64.52,
            "text": " Ugh, he spent weeks building a few-shot learning approach",
            "tokens": [
                50524,
                16506,
                11,
                415,
                4418,
                3259,
                2390,
                257,
                1326,
                12,
                18402,
                2539,
                3109,
                50728
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1487676529657273,
            "compression_ratio": 1.6101190476190477,
            "no_speech_prob": 0.0005119660636410117
        },
        {
            "id": 32,
            "seek": 5724,
            "start": 64.52,
            "end": 66.72,
            "text": " because he said he didn't have enough data,",
            "tokens": [
                50728,
                570,
                415,
                848,
                415,
                994,
                380,
                362,
                1547,
                1412,
                11,
                50838
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1487676529657273,
            "compression_ratio": 1.6101190476190477,
            "no_speech_prob": 0.0005119660636410117
        },
        {
            "id": 33,
            "seek": 5724,
            "start": 66.72,
            "end": 68.04,
            "text": " didn't get anywhere.",
            "tokens": [
                50838,
                994,
                380,
                483,
                4992,
                13,
                50904
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1487676529657273,
            "compression_ratio": 1.6101190476190477,
            "no_speech_prob": 0.0005119660636410117
        },
        {
            "id": 34,
            "seek": 5724,
            "start": 68.04,
            "end": 70.2,
            "text": " We handed the project off to Sarah.",
            "tokens": [
                50904,
                492,
                16013,
                264,
                1716,
                766,
                281,
                9519,
                13,
                51012
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1487676529657273,
            "compression_ratio": 1.6101190476190477,
            "no_speech_prob": 0.0005119660636410117
        },
        {
            "id": 35,
            "seek": 5724,
            "start": 70.2,
            "end": 73.24000000000001,
            "text": " She worked with a business, took a little bit of a free time,",
            "tokens": [
                51012,
                1240,
                2732,
                365,
                257,
                1606,
                11,
                1890,
                257,
                707,
                857,
                295,
                257,
                1737,
                565,
                11,
                51164
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1487676529657273,
            "compression_ratio": 1.6101190476190477,
            "no_speech_prob": 0.0005119660636410117
        },
        {
            "id": 36,
            "seek": 5724,
            "start": 73.24000000000001,
            "end": 75.72,
            "text": " labeled some data, and she was able to quickly",
            "tokens": [
                51164,
                21335,
                512,
                1412,
                11,
                293,
                750,
                390,
                1075,
                281,
                2661,
                51288
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1487676529657273,
            "compression_ratio": 1.6101190476190477,
            "no_speech_prob": 0.0005119660636410117
        },
        {
            "id": 37,
            "seek": 5724,
            "start": 75.72,
            "end": 77.36,
            "text": " build a very effective model",
            "tokens": [
                51288,
                1322,
                257,
                588,
                4942,
                2316,
                51370
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1487676529657273,
            "compression_ratio": 1.6101190476190477,
            "no_speech_prob": 0.0005119660636410117
        },
        {
            "id": 38,
            "seek": 5724,
            "start": 77.36,
            "end": 79.24000000000001,
            "text": " by just taking the time to label data.",
            "tokens": [
                51370,
                538,
                445,
                1940,
                264,
                565,
                281,
                7645,
                1412,
                13,
                51464
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1487676529657273,
            "compression_ratio": 1.6101190476190477,
            "no_speech_prob": 0.0005119660636410117
        },
        {
            "id": 39,
            "seek": 5724,
            "start": 79.24000000000001,
            "end": 80.32000000000001,
            "text": " You data scientist.",
            "tokens": [
                51464,
                509,
                1412,
                12662,
                13,
                51518
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1487676529657273,
            "compression_ratio": 1.6101190476190477,
            "no_speech_prob": 0.0005119660636410117
        },
        {
            "id": 40,
            "seek": 5724,
            "start": 80.32000000000001,
            "end": 82.52000000000001,
            "text": " As the person who has to put these things in a production,",
            "tokens": [
                51518,
                1018,
                264,
                954,
                567,
                575,
                281,
                829,
                613,
                721,
                294,
                257,
                4265,
                11,
                51628
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1487676529657273,
            "compression_ratio": 1.6101190476190477,
            "no_speech_prob": 0.0005119660636410117
        },
        {
            "id": 41,
            "seek": 5724,
            "start": 82.52000000000001,
            "end": 85.12,
            "text": " I much prefer a simpler model.",
            "tokens": [
                51628,
                286,
                709,
                4382,
                257,
                18587,
                2316,
                13,
                51758
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1487676529657273,
            "compression_ratio": 1.6101190476190477,
            "no_speech_prob": 0.0005119660636410117
        },
        {
            "id": 42,
            "seek": 5724,
            "start": 85.12,
            "end": 86.84,
            "text": " They're much easier to understand",
            "tokens": [
                51758,
                814,
                434,
                709,
                3571,
                281,
                1223,
                51844
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1487676529657273,
            "compression_ratio": 1.6101190476190477,
            "no_speech_prob": 0.0005119660636410117
        },
        {
            "id": 43,
            "seek": 8684,
            "start": 86.84,
            "end": 88.52000000000001,
            "text": " when I'm trying to troubleshoot them.",
            "tokens": [
                50364,
                562,
                286,
                478,
                1382,
                281,
                15379,
                24467,
                552,
                13,
                50448
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11610651635504388,
            "compression_ratio": 1.6843657817109146,
            "no_speech_prob": 0.0004583407426252961
        },
        {
            "id": 44,
            "seek": 8684,
            "start": 88.52000000000001,
            "end": 90.4,
            "text": " They take a lot less compute.",
            "tokens": [
                50448,
                814,
                747,
                257,
                688,
                1570,
                14722,
                13,
                50542
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11610651635504388,
            "compression_ratio": 1.6843657817109146,
            "no_speech_prob": 0.0004583407426252961
        },
        {
            "id": 45,
            "seek": 8684,
            "start": 90.4,
            "end": 93.2,
            "text": " If you look at our data quality pipelines that we have,",
            "tokens": [
                50542,
                759,
                291,
                574,
                412,
                527,
                1412,
                3125,
                40168,
                300,
                321,
                362,
                11,
                50682
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11610651635504388,
            "compression_ratio": 1.6843657817109146,
            "no_speech_prob": 0.0004583407426252961
        },
        {
            "id": 46,
            "seek": 8684,
            "start": 93.2,
            "end": 95.88000000000001,
            "text": " they're all using very simple bag of words models.",
            "tokens": [
                50682,
                436,
                434,
                439,
                1228,
                588,
                2199,
                3411,
                295,
                2283,
                5245,
                13,
                50816
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11610651635504388,
            "compression_ratio": 1.6843657817109146,
            "no_speech_prob": 0.0004583407426252961
        },
        {
            "id": 47,
            "seek": 8684,
            "start": 95.88000000000001,
            "end": 98.52000000000001,
            "text": " I know you guys have those fancy transformer models,",
            "tokens": [
                50816,
                286,
                458,
                291,
                1074,
                362,
                729,
                10247,
                31782,
                5245,
                11,
                50948
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11610651635504388,
            "compression_ratio": 1.6843657817109146,
            "no_speech_prob": 0.0004583407426252961
        },
        {
            "id": 48,
            "seek": 8684,
            "start": 98.52000000000001,
            "end": 100.4,
            "text": " but those things take way too much compute,",
            "tokens": [
                50948,
                457,
                729,
                721,
                747,
                636,
                886,
                709,
                14722,
                11,
                51042
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11610651635504388,
            "compression_ratio": 1.6843657817109146,
            "no_speech_prob": 0.0004583407426252961
        },
        {
            "id": 49,
            "seek": 8684,
            "start": 100.4,
            "end": 102.08,
            "text": " way too much resources.",
            "tokens": [
                51042,
                636,
                886,
                709,
                3593,
                13,
                51126
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11610651635504388,
            "compression_ratio": 1.6843657817109146,
            "no_speech_prob": 0.0004583407426252961
        },
        {
            "id": 50,
            "seek": 8684,
            "start": 102.08,
            "end": 104.0,
            "text": " If we can do it with a simple model,",
            "tokens": [
                51126,
                759,
                321,
                393,
                360,
                309,
                365,
                257,
                2199,
                2316,
                11,
                51222
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11610651635504388,
            "compression_ratio": 1.6843657817109146,
            "no_speech_prob": 0.0004583407426252961
        },
        {
            "id": 51,
            "seek": 8684,
            "start": 104.0,
            "end": 105.32000000000001,
            "text": " that's what we're gonna choose.",
            "tokens": [
                51222,
                300,
                311,
                437,
                321,
                434,
                799,
                2826,
                13,
                51288
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11610651635504388,
            "compression_ratio": 1.6843657817109146,
            "no_speech_prob": 0.0004583407426252961
        },
        {
            "id": 52,
            "seek": 8684,
            "start": 105.32000000000001,
            "end": 106.44,
            "text": " That makes a lot of sense.",
            "tokens": [
                51288,
                663,
                1669,
                257,
                688,
                295,
                2020,
                13,
                51344
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11610651635504388,
            "compression_ratio": 1.6843657817109146,
            "no_speech_prob": 0.0004583407426252961
        },
        {
            "id": 53,
            "seek": 8684,
            "start": 106.44,
            "end": 108.48,
            "text": " I should probably brush up on pass meetings",
            "tokens": [
                51344,
                286,
                820,
                1391,
                5287,
                493,
                322,
                1320,
                8410,
                51446
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11610651635504388,
            "compression_ratio": 1.6843657817109146,
            "no_speech_prob": 0.0004583407426252961
        },
        {
            "id": 54,
            "seek": 8684,
            "start": 108.48,
            "end": 110.88,
            "text": " where we talked about using tools like CleanLab",
            "tokens": [
                51446,
                689,
                321,
                2825,
                466,
                1228,
                3873,
                411,
                18463,
                37880,
                51566
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11610651635504388,
            "compression_ratio": 1.6843657817109146,
            "no_speech_prob": 0.0004583407426252961
        },
        {
            "id": 55,
            "seek": 8684,
            "start": 110.88,
            "end": 114.36,
            "text": " as well as doing error analysis with our models.",
            "tokens": [
                51566,
                382,
                731,
                382,
                884,
                6713,
                5215,
                365,
                527,
                5245,
                13,
                51740
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11610651635504388,
            "compression_ratio": 1.6843657817109146,
            "no_speech_prob": 0.0004583407426252961
        },
        {
            "id": 56,
            "seek": 8684,
            "start": 114.36,
            "end": 116.60000000000001,
            "text": " I just saw this data center AI course.",
            "tokens": [
                51740,
                286,
                445,
                1866,
                341,
                1412,
                3056,
                7318,
                1164,
                13,
                51852
            ],
            "temperature": 0.0,
            "avg_logprob": -0.11610651635504388,
            "compression_ratio": 1.6843657817109146,
            "no_speech_prob": 0.0004583407426252961
        },
        {
            "id": 57,
            "seek": 11660,
            "start": 116.64,
            "end": 117.91999999999999,
            "text": " All the videos are free.",
            "tokens": [
                50366,
                1057,
                264,
                2145,
                366,
                1737,
                13,
                50430
            ],
            "temperature": 0.0,
            "avg_logprob": -0.30307088579450336,
            "compression_ratio": 0.9393939393939394,
            "no_speech_prob": 0.0018045238684862852
        },
        {
            "id": 58,
            "seek": 11660,
            "start": 117.91999999999999,
            "end": 119.52,
            "text": " You might want to use it to brush up.",
            "tokens": [
                50430,
                509,
                1062,
                528,
                281,
                764,
                309,
                281,
                5287,
                493,
                13,
                50510
            ],
            "temperature": 0.0,
            "avg_logprob": -0.30307088579450336,
            "compression_ratio": 0.9393939393939394,
            "no_speech_prob": 0.0018045238684862852
        }
    ],
    "language": "en",
    "filename": "2025-02-27_16-55-42_DGlW4V1A0Ri.mp4",
    "account": "rajistics",
    "shortcode": "DGlW4V1A0Ri",
    "timestamp": "2025-02-27T16:55:42",
    "caption": "ML engineers discuss why cutting-edge academic models aren’t production-ready and often don’t justify the implementation costs. They share practical alternatives that work better:\n* Simpler models that need less compute\n* Quality data labeling over complexity\n* Rules-based approaches with domain knowledge\n* Data cleaning tools like cleanlab\nThe key message: understanding your specific problem and data beats chasing the latest complex architectures.",
    "likes": 279,
    "comments": 7,
    "url": "https://www.instagram.com/p/DGlW4V1A0Ri/",
    "username": "rajistics",
    "download_date": "2025-03-11T22:21:17.379056"
}