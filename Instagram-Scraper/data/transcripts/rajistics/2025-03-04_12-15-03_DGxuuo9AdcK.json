{
    "text": " We can't figure out which of our customers to target with marketing. We need your help to do some of your analytics. We could do a customer lifetime analysis, which would allow you to understand how much each customer is worth. Great, how long? Good day or two. This type of problem that needs a calculation, not a good fit for me. I'm out. A couple of weeks, how about Friday? I finished my analysis. Can you walk me through it? Oh boy. I took the transaction date, aggregated it to the customer level. Once I did that, I focused on three different measures. It's common for marketing. The recent C of purchases, the frequency of purchases, and the monetary value of purchase. Using RFM, I was able to estimate the value for each customer. But I also used RFM to score each customer, and I put them into different clusters. So we figure out which ones are our top customers that we should focus on. Which ones just haven't purchased recently? Maybe we should send a discount coupon to them. So this way, marketing can start making decisions based on these groups that I created. Great work. I just need to put the finishing touches on my dashboard. It's almost Friday. Can we review where you're at? I decided to take a machine learning approach to focus on what customers are likely to do, versus what we already know about them. So the first step I did was I took all the data that we had, split it into two areas, one for me to train on, another data set for me to validate, make sure my model is working correctly. Keep going. I built a machine learning model at the customer level. For the features, I used the RFM features, but I also brought in other pieces of information we had, such as where they lived, and their age for that final model. That's great. Can you explain the predictions? Sure. We can use Shap to explain any of the predictions. Oh, I got big plans for the second generation version of this, where we can bring in a variety of different types of features into a neural network architecture. It's going to be awesome. Wow. That would be cool. But let's see if this meets marketing needs, and maybe it's good enough for marketing.",
    "segments": [
        {
            "id": 0,
            "seek": 0,
            "start": 0.0,
            "end": 2.88,
            "text": " We can't figure out which of our customers to target with marketing.",
            "tokens": [
                50364,
                492,
                393,
                380,
                2573,
                484,
                597,
                295,
                527,
                4581,
                281,
                3779,
                365,
                6370,
                13,
                50508
            ],
            "temperature": 0.0,
            "avg_logprob": -0.28733139038085936,
            "compression_ratio": 1.6491803278688524,
            "no_speech_prob": 0.007160756271332502
        },
        {
            "id": 1,
            "seek": 0,
            "start": 2.88,
            "end": 5.04,
            "text": " We need your help to do some of your analytics.",
            "tokens": [
                50508,
                492,
                643,
                428,
                854,
                281,
                360,
                512,
                295,
                428,
                15370,
                13,
                50616
            ],
            "temperature": 0.0,
            "avg_logprob": -0.28733139038085936,
            "compression_ratio": 1.6491803278688524,
            "no_speech_prob": 0.007160756271332502
        },
        {
            "id": 2,
            "seek": 0,
            "start": 5.04,
            "end": 9.5,
            "text": " We could do a customer lifetime analysis, which would allow you to understand how much each customer is worth.",
            "tokens": [
                50616,
                492,
                727,
                360,
                257,
                5474,
                11364,
                5215,
                11,
                597,
                576,
                2089,
                291,
                281,
                1223,
                577,
                709,
                1184,
                5474,
                307,
                3163,
                13,
                50839
            ],
            "temperature": 0.0,
            "avg_logprob": -0.28733139038085936,
            "compression_ratio": 1.6491803278688524,
            "no_speech_prob": 0.007160756271332502
        },
        {
            "id": 3,
            "seek": 0,
            "start": 9.5,
            "end": 10.5,
            "text": " Great, how long?",
            "tokens": [
                50839,
                3769,
                11,
                577,
                938,
                30,
                50889
            ],
            "temperature": 0.0,
            "avg_logprob": -0.28733139038085936,
            "compression_ratio": 1.6491803278688524,
            "no_speech_prob": 0.007160756271332502
        },
        {
            "id": 4,
            "seek": 0,
            "start": 10.5,
            "end": 11.3,
            "text": " Good day or two.",
            "tokens": [
                50889,
                2205,
                786,
                420,
                732,
                13,
                50929
            ],
            "temperature": 0.0,
            "avg_logprob": -0.28733139038085936,
            "compression_ratio": 1.6491803278688524,
            "no_speech_prob": 0.007160756271332502
        },
        {
            "id": 5,
            "seek": 0,
            "start": 11.3,
            "end": 14.66,
            "text": " This type of problem that needs a calculation, not a good fit for me.",
            "tokens": [
                50929,
                639,
                2010,
                295,
                1154,
                300,
                2203,
                257,
                17108,
                11,
                406,
                257,
                665,
                3318,
                337,
                385,
                13,
                51097
            ],
            "temperature": 0.0,
            "avg_logprob": -0.28733139038085936,
            "compression_ratio": 1.6491803278688524,
            "no_speech_prob": 0.007160756271332502
        },
        {
            "id": 6,
            "seek": 0,
            "start": 14.66,
            "end": 15.26,
            "text": " I'm out.",
            "tokens": [
                51097,
                286,
                478,
                484,
                13,
                51127
            ],
            "temperature": 0.0,
            "avg_logprob": -0.28733139038085936,
            "compression_ratio": 1.6491803278688524,
            "no_speech_prob": 0.007160756271332502
        },
        {
            "id": 7,
            "seek": 0,
            "start": 15.26,
            "end": 16.9,
            "text": " A couple of weeks, how about Friday?",
            "tokens": [
                51127,
                316,
                1916,
                295,
                3259,
                11,
                577,
                466,
                6984,
                30,
                51209
            ],
            "temperature": 0.0,
            "avg_logprob": -0.28733139038085936,
            "compression_ratio": 1.6491803278688524,
            "no_speech_prob": 0.007160756271332502
        },
        {
            "id": 8,
            "seek": 0,
            "start": 16.9,
            "end": 21.06,
            "text": " I finished my analysis.",
            "tokens": [
                51209,
                286,
                4335,
                452,
                5215,
                13,
                51417
            ],
            "temperature": 0.0,
            "avg_logprob": -0.28733139038085936,
            "compression_ratio": 1.6491803278688524,
            "no_speech_prob": 0.007160756271332502
        },
        {
            "id": 9,
            "seek": 0,
            "start": 21.06,
            "end": 22.1,
            "text": " Can you walk me through it?",
            "tokens": [
                51417,
                1664,
                291,
                1792,
                385,
                807,
                309,
                30,
                51469
            ],
            "temperature": 0.0,
            "avg_logprob": -0.28733139038085936,
            "compression_ratio": 1.6491803278688524,
            "no_speech_prob": 0.007160756271332502
        },
        {
            "id": 10,
            "seek": 0,
            "start": 22.1,
            "end": 23.14,
            "text": " Oh boy.",
            "tokens": [
                51469,
                876,
                3237,
                13,
                51521
            ],
            "temperature": 0.0,
            "avg_logprob": -0.28733139038085936,
            "compression_ratio": 1.6491803278688524,
            "no_speech_prob": 0.007160756271332502
        },
        {
            "id": 11,
            "seek": 0,
            "start": 23.14,
            "end": 26.5,
            "text": " I took the transaction date, aggregated it to the customer level.",
            "tokens": [
                51521,
                286,
                1890,
                264,
                14425,
                4002,
                11,
                16743,
                770,
                309,
                281,
                264,
                5474,
                1496,
                13,
                51689
            ],
            "temperature": 0.0,
            "avg_logprob": -0.28733139038085936,
            "compression_ratio": 1.6491803278688524,
            "no_speech_prob": 0.007160756271332502
        },
        {
            "id": 12,
            "seek": 2650,
            "start": 26.66,
            "end": 29.66,
            "text": " Once I did that, I focused on three different measures.",
            "tokens": [
                50372,
                3443,
                286,
                630,
                300,
                11,
                286,
                5178,
                322,
                1045,
                819,
                8000,
                13,
                50522
            ],
            "temperature": 0.0,
            "avg_logprob": -0.191656159572914,
            "compression_ratio": 1.7330960854092528,
            "no_speech_prob": 0.010088710114359856
        },
        {
            "id": 13,
            "seek": 2650,
            "start": 29.66,
            "end": 31.14,
            "text": " It's common for marketing.",
            "tokens": [
                50522,
                467,
                311,
                2689,
                337,
                6370,
                13,
                50596
            ],
            "temperature": 0.0,
            "avg_logprob": -0.191656159572914,
            "compression_ratio": 1.7330960854092528,
            "no_speech_prob": 0.010088710114359856
        },
        {
            "id": 14,
            "seek": 2650,
            "start": 31.14,
            "end": 36.18,
            "text": " The recent C of purchases, the frequency of purchases, and the monetary value of purchase.",
            "tokens": [
                50596,
                440,
                5162,
                383,
                295,
                26762,
                11,
                264,
                7893,
                295,
                26762,
                11,
                293,
                264,
                26388,
                2158,
                295,
                8110,
                13,
                50848
            ],
            "temperature": 0.0,
            "avg_logprob": -0.191656159572914,
            "compression_ratio": 1.7330960854092528,
            "no_speech_prob": 0.010088710114359856
        },
        {
            "id": 15,
            "seek": 2650,
            "start": 36.18,
            "end": 39.46,
            "text": " Using RFM, I was able to estimate the value for each customer.",
            "tokens": [
                50848,
                11142,
                26204,
                44,
                11,
                286,
                390,
                1075,
                281,
                12539,
                264,
                2158,
                337,
                1184,
                5474,
                13,
                51012
            ],
            "temperature": 0.0,
            "avg_logprob": -0.191656159572914,
            "compression_ratio": 1.7330960854092528,
            "no_speech_prob": 0.010088710114359856
        },
        {
            "id": 16,
            "seek": 2650,
            "start": 39.46,
            "end": 45.3,
            "text": " But I also used RFM to score each customer, and I put them into different clusters.",
            "tokens": [
                51012,
                583,
                286,
                611,
                1143,
                26204,
                44,
                281,
                6175,
                1184,
                5474,
                11,
                293,
                286,
                829,
                552,
                666,
                819,
                23313,
                13,
                51304
            ],
            "temperature": 0.0,
            "avg_logprob": -0.191656159572914,
            "compression_ratio": 1.7330960854092528,
            "no_speech_prob": 0.010088710114359856
        },
        {
            "id": 17,
            "seek": 2650,
            "start": 45.3,
            "end": 48.980000000000004,
            "text": " So we figure out which ones are our top customers that we should focus on.",
            "tokens": [
                51304,
                407,
                321,
                2573,
                484,
                597,
                2306,
                366,
                527,
                1192,
                4581,
                300,
                321,
                820,
                1879,
                322,
                13,
                51488
            ],
            "temperature": 0.0,
            "avg_logprob": -0.191656159572914,
            "compression_ratio": 1.7330960854092528,
            "no_speech_prob": 0.010088710114359856
        },
        {
            "id": 18,
            "seek": 2650,
            "start": 48.980000000000004,
            "end": 50.900000000000006,
            "text": " Which ones just haven't purchased recently?",
            "tokens": [
                51488,
                3013,
                2306,
                445,
                2378,
                380,
                14734,
                3938,
                30,
                51584
            ],
            "temperature": 0.0,
            "avg_logprob": -0.191656159572914,
            "compression_ratio": 1.7330960854092528,
            "no_speech_prob": 0.010088710114359856
        },
        {
            "id": 19,
            "seek": 2650,
            "start": 50.900000000000006,
            "end": 53.1,
            "text": " Maybe we should send a discount coupon to them.",
            "tokens": [
                51584,
                2704,
                321,
                820,
                2845,
                257,
                11635,
                33390,
                281,
                552,
                13,
                51694
            ],
            "temperature": 0.0,
            "avg_logprob": -0.191656159572914,
            "compression_ratio": 1.7330960854092528,
            "no_speech_prob": 0.010088710114359856
        },
        {
            "id": 20,
            "seek": 5310,
            "start": 53.1,
            "end": 58.02,
            "text": " So this way, marketing can start making decisions based on these groups that I created.",
            "tokens": [
                50364,
                407,
                341,
                636,
                11,
                6370,
                393,
                722,
                1455,
                5327,
                2361,
                322,
                613,
                3935,
                300,
                286,
                2942,
                13,
                50610
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16655296379036003,
            "compression_ratio": 1.6483180428134556,
            "no_speech_prob": 0.005114808678627014
        },
        {
            "id": 21,
            "seek": 5310,
            "start": 58.02,
            "end": 59.46,
            "text": " Great work.",
            "tokens": [
                50610,
                3769,
                589,
                13,
                50682
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16655296379036003,
            "compression_ratio": 1.6483180428134556,
            "no_speech_prob": 0.005114808678627014
        },
        {
            "id": 22,
            "seek": 5310,
            "start": 59.46,
            "end": 61.86,
            "text": " I just need to put the finishing touches on my dashboard.",
            "tokens": [
                50682,
                286,
                445,
                643,
                281,
                829,
                264,
                12693,
                17431,
                322,
                452,
                18342,
                13,
                50802
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16655296379036003,
            "compression_ratio": 1.6483180428134556,
            "no_speech_prob": 0.005114808678627014
        },
        {
            "id": 23,
            "seek": 5310,
            "start": 61.86,
            "end": 62.86,
            "text": " It's almost Friday.",
            "tokens": [
                50802,
                467,
                311,
                1920,
                6984,
                13,
                50852
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16655296379036003,
            "compression_ratio": 1.6483180428134556,
            "no_speech_prob": 0.005114808678627014
        },
        {
            "id": 24,
            "seek": 5310,
            "start": 62.86,
            "end": 63.86,
            "text": " Can we review where you're at?",
            "tokens": [
                50852,
                1664,
                321,
                3131,
                689,
                291,
                434,
                412,
                30,
                50902
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16655296379036003,
            "compression_ratio": 1.6483180428134556,
            "no_speech_prob": 0.005114808678627014
        },
        {
            "id": 25,
            "seek": 5310,
            "start": 63.86,
            "end": 68.26,
            "text": " I decided to take a machine learning approach to focus on what customers are likely to do,",
            "tokens": [
                50902,
                286,
                3047,
                281,
                747,
                257,
                3479,
                2539,
                3109,
                281,
                1879,
                322,
                437,
                4581,
                366,
                3700,
                281,
                360,
                11,
                51122
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16655296379036003,
            "compression_ratio": 1.6483180428134556,
            "no_speech_prob": 0.005114808678627014
        },
        {
            "id": 26,
            "seek": 5310,
            "start": 68.26,
            "end": 70.18,
            "text": " versus what we already know about them.",
            "tokens": [
                51122,
                5717,
                437,
                321,
                1217,
                458,
                466,
                552,
                13,
                51218
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16655296379036003,
            "compression_ratio": 1.6483180428134556,
            "no_speech_prob": 0.005114808678627014
        },
        {
            "id": 27,
            "seek": 5310,
            "start": 70.18,
            "end": 75.22,
            "text": " So the first step I did was I took all the data that we had, split it into two areas,",
            "tokens": [
                51218,
                407,
                264,
                700,
                1823,
                286,
                630,
                390,
                286,
                1890,
                439,
                264,
                1412,
                300,
                321,
                632,
                11,
                7472,
                309,
                666,
                732,
                3179,
                11,
                51470
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16655296379036003,
            "compression_ratio": 1.6483180428134556,
            "no_speech_prob": 0.005114808678627014
        },
        {
            "id": 28,
            "seek": 5310,
            "start": 75.22,
            "end": 79.54,
            "text": " one for me to train on, another data set for me to validate, make sure my model is working",
            "tokens": [
                51470,
                472,
                337,
                385,
                281,
                3847,
                322,
                11,
                1071,
                1412,
                992,
                337,
                385,
                281,
                29562,
                11,
                652,
                988,
                452,
                2316,
                307,
                1364,
                51686
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16655296379036003,
            "compression_ratio": 1.6483180428134556,
            "no_speech_prob": 0.005114808678627014
        },
        {
            "id": 29,
            "seek": 5310,
            "start": 79.54,
            "end": 80.54,
            "text": " correctly.",
            "tokens": [
                51686,
                8944,
                13,
                51736
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16655296379036003,
            "compression_ratio": 1.6483180428134556,
            "no_speech_prob": 0.005114808678627014
        },
        {
            "id": 30,
            "seek": 5310,
            "start": 80.54,
            "end": 81.54,
            "text": " Keep going.",
            "tokens": [
                51736,
                5527,
                516,
                13,
                51786
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16655296379036003,
            "compression_ratio": 1.6483180428134556,
            "no_speech_prob": 0.005114808678627014
        },
        {
            "id": 31,
            "seek": 8154,
            "start": 81.54,
            "end": 84.18,
            "text": " I built a machine learning model at the customer level.",
            "tokens": [
                50364,
                286,
                3094,
                257,
                3479,
                2539,
                2316,
                412,
                264,
                5474,
                1496,
                13,
                50496
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16619532282759503,
            "compression_ratio": 1.732590529247911,
            "no_speech_prob": 0.022515717893838882
        },
        {
            "id": 32,
            "seek": 8154,
            "start": 84.18,
            "end": 88.46000000000001,
            "text": " For the features, I used the RFM features, but I also brought in other pieces of information",
            "tokens": [
                50496,
                1171,
                264,
                4122,
                11,
                286,
                1143,
                264,
                26204,
                44,
                4122,
                11,
                457,
                286,
                611,
                3038,
                294,
                661,
                3755,
                295,
                1589,
                50710
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16619532282759503,
            "compression_ratio": 1.732590529247911,
            "no_speech_prob": 0.022515717893838882
        },
        {
            "id": 33,
            "seek": 8154,
            "start": 88.46000000000001,
            "end": 92.74000000000001,
            "text": " we had, such as where they lived, and their age for that final model.",
            "tokens": [
                50710,
                321,
                632,
                11,
                1270,
                382,
                689,
                436,
                5152,
                11,
                293,
                641,
                3205,
                337,
                300,
                2572,
                2316,
                13,
                50924
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16619532282759503,
            "compression_ratio": 1.732590529247911,
            "no_speech_prob": 0.022515717893838882
        },
        {
            "id": 34,
            "seek": 8154,
            "start": 92.74000000000001,
            "end": 93.74000000000001,
            "text": " That's great.",
            "tokens": [
                50924,
                663,
                311,
                869,
                13,
                50974
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16619532282759503,
            "compression_ratio": 1.732590529247911,
            "no_speech_prob": 0.022515717893838882
        },
        {
            "id": 35,
            "seek": 8154,
            "start": 93.74000000000001,
            "end": 94.74000000000001,
            "text": " Can you explain the predictions?",
            "tokens": [
                50974,
                1664,
                291,
                2903,
                264,
                21264,
                30,
                51024
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16619532282759503,
            "compression_ratio": 1.732590529247911,
            "no_speech_prob": 0.022515717893838882
        },
        {
            "id": 36,
            "seek": 8154,
            "start": 94.74000000000001,
            "end": 95.74000000000001,
            "text": " Sure.",
            "tokens": [
                51024,
                4894,
                13,
                51074
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16619532282759503,
            "compression_ratio": 1.732590529247911,
            "no_speech_prob": 0.022515717893838882
        },
        {
            "id": 37,
            "seek": 8154,
            "start": 95.74000000000001,
            "end": 96.74000000000001,
            "text": " We can use Shap to explain any of the predictions.",
            "tokens": [
                51074,
                492,
                393,
                764,
                1160,
                569,
                281,
                2903,
                604,
                295,
                264,
                21264,
                13,
                51124
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16619532282759503,
            "compression_ratio": 1.732590529247911,
            "no_speech_prob": 0.022515717893838882
        },
        {
            "id": 38,
            "seek": 8154,
            "start": 96.74000000000001,
            "end": 101.06,
            "text": " Oh, I got big plans for the second generation version of this, where we can bring in a variety",
            "tokens": [
                51124,
                876,
                11,
                286,
                658,
                955,
                5482,
                337,
                264,
                1150,
                5125,
                3037,
                295,
                341,
                11,
                689,
                321,
                393,
                1565,
                294,
                257,
                5673,
                51340
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16619532282759503,
            "compression_ratio": 1.732590529247911,
            "no_speech_prob": 0.022515717893838882
        },
        {
            "id": 39,
            "seek": 8154,
            "start": 101.06,
            "end": 103.58000000000001,
            "text": " of different types of features into a neural network architecture.",
            "tokens": [
                51340,
                295,
                819,
                3467,
                295,
                4122,
                666,
                257,
                18161,
                3209,
                9482,
                13,
                51466
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16619532282759503,
            "compression_ratio": 1.732590529247911,
            "no_speech_prob": 0.022515717893838882
        },
        {
            "id": 40,
            "seek": 8154,
            "start": 103.58000000000001,
            "end": 104.98,
            "text": " It's going to be awesome.",
            "tokens": [
                51466,
                467,
                311,
                516,
                281,
                312,
                3476,
                13,
                51536
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16619532282759503,
            "compression_ratio": 1.732590529247911,
            "no_speech_prob": 0.022515717893838882
        },
        {
            "id": 41,
            "seek": 8154,
            "start": 104.98,
            "end": 105.98,
            "text": " Wow.",
            "tokens": [
                51536,
                3153,
                13,
                51586
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16619532282759503,
            "compression_ratio": 1.732590529247911,
            "no_speech_prob": 0.022515717893838882
        },
        {
            "id": 42,
            "seek": 8154,
            "start": 105.98,
            "end": 106.98,
            "text": " That would be cool.",
            "tokens": [
                51586,
                663,
                576,
                312,
                1627,
                13,
                51636
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16619532282759503,
            "compression_ratio": 1.732590529247911,
            "no_speech_prob": 0.022515717893838882
        },
        {
            "id": 43,
            "seek": 8154,
            "start": 106.98,
            "end": 109.5,
            "text": " But let's see if this meets marketing needs, and maybe it's good enough for marketing.",
            "tokens": [
                51636,
                583,
                718,
                311,
                536,
                498,
                341,
                13961,
                6370,
                2203,
                11,
                293,
                1310,
                309,
                311,
                665,
                1547,
                337,
                6370,
                13,
                51762
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16619532282759503,
            "compression_ratio": 1.732590529247911,
            "no_speech_prob": 0.022515717893838882
        }
    ],
    "language": "en",
    "filename": "2025-03-04_12-15-03_DGxuuo9AdcK.mp4",
    "account": "rajistics",
    "shortcode": "DGxuuo9AdcK",
    "timestamp": "2025-03-04T12:15:03",
    "caption": "Customer lifetime analysis is a classic use case",
    "likes": 137,
    "comments": 1,
    "url": "https://www.instagram.com/p/DGxuuo9AdcK/",
    "username": "rajistics",
    "download_date": "2025-03-11T22:20:47.469252"
}