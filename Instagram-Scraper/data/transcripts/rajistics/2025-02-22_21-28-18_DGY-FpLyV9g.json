{
    "text": " You just sign an exclusive contract for AGI LM. Just imagine all the AI problems your team's gonna be able to do. New things, nah, let's use this as a way to downsize some of our existing pipelines and contracts. Replacing? Oh, that doesn't sound right. I want your team to do new things, AGI. Let's start by replacing about a dozen of our different NLP pipelines around classification, summarization, extraction. All we have to do now is prompt, easy peasy. How much money does that say? It's a little higher compute cost, but we save a ton of time around data prep, building and training those models and maintaining those pipelines. Beautiful. Sell me more. We'll also be able to reduce our use of Google translate and human translators by just taking advantage of our models. Because after all, our customers don't expect perfection. Less overhead, fewer people, music to my ears. Sell me more. Well, let's not get too carried away. We still need a little bit of human oversight, but some things like data annotation, we're going to be able to use AI now for creating synthetic data, saving us a ton. This AI is wonderful. Now, can you do me one thing? Can you take care of all those stinky developers tired of seeing Birkenstocks everywhere? Well, LLUMs are allowing our developers to become more productive, about 20% of our code now in our code bases generated from AI. So I think you'll be seeing a lot less developers around. Wow, this is incredible. Why didn't you just do this when we hired you five years ago? But anyways, what's next? Well, AI's getting better at persuasion, setting unrealistic goals, and overusing jargon like synergy and circle back around. So I think it's coming for your job next.",
    "segments": [
        {
            "id": 0,
            "seek": 0,
            "start": 0.0,
            "end": 3.8000000000000003,
            "text": " You just sign an exclusive contract for AGI LM.",
            "tokens": [
                50364,
                509,
                445,
                1465,
                364,
                13005,
                4364,
                337,
                316,
                26252,
                441,
                44,
                13,
                50554
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17395571728686351,
            "compression_ratio": 1.6212624584717608,
            "no_speech_prob": 0.012053419835865498
        },
        {
            "id": 1,
            "seek": 0,
            "start": 3.8000000000000003,
            "end": 6.28,
            "text": " Just imagine all the AI problems",
            "tokens": [
                50554,
                1449,
                3811,
                439,
                264,
                7318,
                2740,
                50678
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17395571728686351,
            "compression_ratio": 1.6212624584717608,
            "no_speech_prob": 0.012053419835865498
        },
        {
            "id": 2,
            "seek": 0,
            "start": 6.28,
            "end": 7.6000000000000005,
            "text": " your team's gonna be able to do.",
            "tokens": [
                50678,
                428,
                1469,
                311,
                799,
                312,
                1075,
                281,
                360,
                13,
                50744
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17395571728686351,
            "compression_ratio": 1.6212624584717608,
            "no_speech_prob": 0.012053419835865498
        },
        {
            "id": 3,
            "seek": 0,
            "start": 7.6000000000000005,
            "end": 9.8,
            "text": " New things, nah, let's use this as a way",
            "tokens": [
                50744,
                1873,
                721,
                11,
                17170,
                11,
                718,
                311,
                764,
                341,
                382,
                257,
                636,
                50854
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17395571728686351,
            "compression_ratio": 1.6212624584717608,
            "no_speech_prob": 0.012053419835865498
        },
        {
            "id": 4,
            "seek": 0,
            "start": 9.8,
            "end": 12.44,
            "text": " to downsize some of our existing pipelines and contracts.",
            "tokens": [
                50854,
                281,
                21554,
                1125,
                512,
                295,
                527,
                6741,
                40168,
                293,
                13952,
                13,
                50986
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17395571728686351,
            "compression_ratio": 1.6212624584717608,
            "no_speech_prob": 0.012053419835865498
        },
        {
            "id": 5,
            "seek": 0,
            "start": 12.44,
            "end": 13.44,
            "text": " Replacing?",
            "tokens": [
                50986,
                47762,
                5615,
                30,
                51036
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17395571728686351,
            "compression_ratio": 1.6212624584717608,
            "no_speech_prob": 0.012053419835865498
        },
        {
            "id": 6,
            "seek": 0,
            "start": 13.44,
            "end": 14.68,
            "text": " Oh, that doesn't sound right.",
            "tokens": [
                51036,
                876,
                11,
                300,
                1177,
                380,
                1626,
                558,
                13,
                51098
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17395571728686351,
            "compression_ratio": 1.6212624584717608,
            "no_speech_prob": 0.012053419835865498
        },
        {
            "id": 7,
            "seek": 0,
            "start": 14.68,
            "end": 17.12,
            "text": " I want your team to do new things, AGI.",
            "tokens": [
                51098,
                286,
                528,
                428,
                1469,
                281,
                360,
                777,
                721,
                11,
                316,
                26252,
                13,
                51220
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17395571728686351,
            "compression_ratio": 1.6212624584717608,
            "no_speech_prob": 0.012053419835865498
        },
        {
            "id": 8,
            "seek": 0,
            "start": 17.12,
            "end": 18.96,
            "text": " Let's start by replacing about a dozen",
            "tokens": [
                51220,
                961,
                311,
                722,
                538,
                19139,
                466,
                257,
                16654,
                51312
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17395571728686351,
            "compression_ratio": 1.6212624584717608,
            "no_speech_prob": 0.012053419835865498
        },
        {
            "id": 9,
            "seek": 0,
            "start": 18.96,
            "end": 20.84,
            "text": " of our different NLP pipelines",
            "tokens": [
                51312,
                295,
                527,
                819,
                426,
                45196,
                40168,
                51406
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17395571728686351,
            "compression_ratio": 1.6212624584717608,
            "no_speech_prob": 0.012053419835865498
        },
        {
            "id": 10,
            "seek": 0,
            "start": 20.84,
            "end": 24.76,
            "text": " around classification, summarization, extraction.",
            "tokens": [
                51406,
                926,
                21538,
                11,
                14611,
                2144,
                11,
                30197,
                13,
                51602
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17395571728686351,
            "compression_ratio": 1.6212624584717608,
            "no_speech_prob": 0.012053419835865498
        },
        {
            "id": 11,
            "seek": 0,
            "start": 24.76,
            "end": 27.400000000000002,
            "text": " All we have to do now is prompt, easy peasy.",
            "tokens": [
                51602,
                1057,
                321,
                362,
                281,
                360,
                586,
                307,
                12391,
                11,
                1858,
                520,
                5871,
                13,
                51734
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17395571728686351,
            "compression_ratio": 1.6212624584717608,
            "no_speech_prob": 0.012053419835865498
        },
        {
            "id": 12,
            "seek": 0,
            "start": 27.400000000000002,
            "end": 29.2,
            "text": " How much money does that say?",
            "tokens": [
                51734,
                1012,
                709,
                1460,
                775,
                300,
                584,
                30,
                51824
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17395571728686351,
            "compression_ratio": 1.6212624584717608,
            "no_speech_prob": 0.012053419835865498
        },
        {
            "id": 13,
            "seek": 2920,
            "start": 29.2,
            "end": 30.72,
            "text": " It's a little higher compute cost,",
            "tokens": [
                50364,
                467,
                311,
                257,
                707,
                2946,
                14722,
                2063,
                11,
                50440
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1453985773531118,
            "compression_ratio": 1.6745762711864407,
            "no_speech_prob": 0.0021665680687874556
        },
        {
            "id": 14,
            "seek": 2920,
            "start": 30.72,
            "end": 33.519999999999996,
            "text": " but we save a ton of time around data prep,",
            "tokens": [
                50440,
                457,
                321,
                3155,
                257,
                2952,
                295,
                565,
                926,
                1412,
                2666,
                11,
                50580
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1453985773531118,
            "compression_ratio": 1.6745762711864407,
            "no_speech_prob": 0.0021665680687874556
        },
        {
            "id": 15,
            "seek": 2920,
            "start": 33.519999999999996,
            "end": 35.32,
            "text": " building and training those models",
            "tokens": [
                50580,
                2390,
                293,
                3097,
                729,
                5245,
                50670
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1453985773531118,
            "compression_ratio": 1.6745762711864407,
            "no_speech_prob": 0.0021665680687874556
        },
        {
            "id": 16,
            "seek": 2920,
            "start": 35.32,
            "end": 37.12,
            "text": " and maintaining those pipelines.",
            "tokens": [
                50670,
                293,
                14916,
                729,
                40168,
                13,
                50760
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1453985773531118,
            "compression_ratio": 1.6745762711864407,
            "no_speech_prob": 0.0021665680687874556
        },
        {
            "id": 17,
            "seek": 2920,
            "start": 37.12,
            "end": 38.2,
            "text": " Beautiful.",
            "tokens": [
                50760,
                14724,
                13,
                50814
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1453985773531118,
            "compression_ratio": 1.6745762711864407,
            "no_speech_prob": 0.0021665680687874556
        },
        {
            "id": 18,
            "seek": 2920,
            "start": 38.2,
            "end": 39.36,
            "text": " Sell me more.",
            "tokens": [
                50814,
                44296,
                385,
                544,
                13,
                50872
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1453985773531118,
            "compression_ratio": 1.6745762711864407,
            "no_speech_prob": 0.0021665680687874556
        },
        {
            "id": 19,
            "seek": 2920,
            "start": 39.36,
            "end": 42.4,
            "text": " We'll also be able to reduce our use of Google translate",
            "tokens": [
                50872,
                492,
                603,
                611,
                312,
                1075,
                281,
                5407,
                527,
                764,
                295,
                3329,
                13799,
                51024
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1453985773531118,
            "compression_ratio": 1.6745762711864407,
            "no_speech_prob": 0.0021665680687874556
        },
        {
            "id": 20,
            "seek": 2920,
            "start": 42.4,
            "end": 46.28,
            "text": " and human translators by just taking advantage of our models.",
            "tokens": [
                51024,
                293,
                1952,
                5105,
                3391,
                538,
                445,
                1940,
                5002,
                295,
                527,
                5245,
                13,
                51218
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1453985773531118,
            "compression_ratio": 1.6745762711864407,
            "no_speech_prob": 0.0021665680687874556
        },
        {
            "id": 21,
            "seek": 2920,
            "start": 46.28,
            "end": 49.04,
            "text": " Because after all, our customers don't expect perfection.",
            "tokens": [
                51218,
                1436,
                934,
                439,
                11,
                527,
                4581,
                500,
                380,
                2066,
                19708,
                13,
                51356
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1453985773531118,
            "compression_ratio": 1.6745762711864407,
            "no_speech_prob": 0.0021665680687874556
        },
        {
            "id": 22,
            "seek": 2920,
            "start": 49.04,
            "end": 53.28,
            "text": " Less overhead, fewer people, music to my ears.",
            "tokens": [
                51356,
                18649,
                19922,
                11,
                13366,
                561,
                11,
                1318,
                281,
                452,
                8798,
                13,
                51568
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1453985773531118,
            "compression_ratio": 1.6745762711864407,
            "no_speech_prob": 0.0021665680687874556
        },
        {
            "id": 23,
            "seek": 2920,
            "start": 53.28,
            "end": 54.4,
            "text": " Sell me more.",
            "tokens": [
                51568,
                44296,
                385,
                544,
                13,
                51624
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1453985773531118,
            "compression_ratio": 1.6745762711864407,
            "no_speech_prob": 0.0021665680687874556
        },
        {
            "id": 24,
            "seek": 2920,
            "start": 54.4,
            "end": 55.8,
            "text": " Well, let's not get too carried away.",
            "tokens": [
                51624,
                1042,
                11,
                718,
                311,
                406,
                483,
                886,
                9094,
                1314,
                13,
                51694
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1453985773531118,
            "compression_ratio": 1.6745762711864407,
            "no_speech_prob": 0.0021665680687874556
        },
        {
            "id": 25,
            "seek": 2920,
            "start": 55.8,
            "end": 58.0,
            "text": " We still need a little bit of human oversight,",
            "tokens": [
                51694,
                492,
                920,
                643,
                257,
                707,
                857,
                295,
                1952,
                29146,
                11,
                51804
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1453985773531118,
            "compression_ratio": 1.6745762711864407,
            "no_speech_prob": 0.0021665680687874556
        },
        {
            "id": 26,
            "seek": 5800,
            "start": 58.0,
            "end": 60.12,
            "text": " but some things like data annotation,",
            "tokens": [
                50364,
                457,
                512,
                721,
                411,
                1412,
                48654,
                11,
                50470
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17838196407090748,
            "compression_ratio": 1.6077844311377245,
            "no_speech_prob": 0.0003749398747459054
        },
        {
            "id": 27,
            "seek": 5800,
            "start": 60.12,
            "end": 61.88,
            "text": " we're going to be able to use AI now",
            "tokens": [
                50470,
                321,
                434,
                516,
                281,
                312,
                1075,
                281,
                764,
                7318,
                586,
                50558
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17838196407090748,
            "compression_ratio": 1.6077844311377245,
            "no_speech_prob": 0.0003749398747459054
        },
        {
            "id": 28,
            "seek": 5800,
            "start": 61.88,
            "end": 64.96,
            "text": " for creating synthetic data, saving us a ton.",
            "tokens": [
                50558,
                337,
                4084,
                23420,
                1412,
                11,
                6816,
                505,
                257,
                2952,
                13,
                50712
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17838196407090748,
            "compression_ratio": 1.6077844311377245,
            "no_speech_prob": 0.0003749398747459054
        },
        {
            "id": 29,
            "seek": 5800,
            "start": 64.96,
            "end": 66.52,
            "text": " This AI is wonderful.",
            "tokens": [
                50712,
                639,
                7318,
                307,
                3715,
                13,
                50790
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17838196407090748,
            "compression_ratio": 1.6077844311377245,
            "no_speech_prob": 0.0003749398747459054
        },
        {
            "id": 30,
            "seek": 5800,
            "start": 66.52,
            "end": 68.32,
            "text": " Now, can you do me one thing?",
            "tokens": [
                50790,
                823,
                11,
                393,
                291,
                360,
                385,
                472,
                551,
                30,
                50880
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17838196407090748,
            "compression_ratio": 1.6077844311377245,
            "no_speech_prob": 0.0003749398747459054
        },
        {
            "id": 31,
            "seek": 5800,
            "start": 68.32,
            "end": 71.04,
            "text": " Can you take care of all those stinky developers",
            "tokens": [
                50880,
                1664,
                291,
                747,
                1127,
                295,
                439,
                729,
                46449,
                8849,
                51016
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17838196407090748,
            "compression_ratio": 1.6077844311377245,
            "no_speech_prob": 0.0003749398747459054
        },
        {
            "id": 32,
            "seek": 5800,
            "start": 71.04,
            "end": 73.2,
            "text": " tired of seeing Birkenstocks everywhere?",
            "tokens": [
                51016,
                5868,
                295,
                2577,
                7145,
                2653,
                23914,
                82,
                5315,
                30,
                51124
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17838196407090748,
            "compression_ratio": 1.6077844311377245,
            "no_speech_prob": 0.0003749398747459054
        },
        {
            "id": 33,
            "seek": 5800,
            "start": 73.2,
            "end": 75.2,
            "text": " Well, LLUMs are allowing our developers",
            "tokens": [
                51124,
                1042,
                11,
                441,
                43,
                14340,
                82,
                366,
                8293,
                527,
                8849,
                51224
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17838196407090748,
            "compression_ratio": 1.6077844311377245,
            "no_speech_prob": 0.0003749398747459054
        },
        {
            "id": 34,
            "seek": 5800,
            "start": 75.2,
            "end": 76.56,
            "text": " to become more productive,",
            "tokens": [
                51224,
                281,
                1813,
                544,
                13304,
                11,
                51292
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17838196407090748,
            "compression_ratio": 1.6077844311377245,
            "no_speech_prob": 0.0003749398747459054
        },
        {
            "id": 35,
            "seek": 5800,
            "start": 76.56,
            "end": 80.8,
            "text": " about 20% of our code now in our code bases generated from AI.",
            "tokens": [
                51292,
                466,
                945,
                4,
                295,
                527,
                3089,
                586,
                294,
                527,
                3089,
                17949,
                10833,
                490,
                7318,
                13,
                51504
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17838196407090748,
            "compression_ratio": 1.6077844311377245,
            "no_speech_prob": 0.0003749398747459054
        },
        {
            "id": 36,
            "seek": 5800,
            "start": 80.8,
            "end": 83.24000000000001,
            "text": " So I think you'll be seeing a lot less developers around.",
            "tokens": [
                51504,
                407,
                286,
                519,
                291,
                603,
                312,
                2577,
                257,
                688,
                1570,
                8849,
                926,
                13,
                51626
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17838196407090748,
            "compression_ratio": 1.6077844311377245,
            "no_speech_prob": 0.0003749398747459054
        },
        {
            "id": 37,
            "seek": 5800,
            "start": 83.24000000000001,
            "end": 85.16,
            "text": " Wow, this is incredible.",
            "tokens": [
                51626,
                3153,
                11,
                341,
                307,
                4651,
                13,
                51722
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17838196407090748,
            "compression_ratio": 1.6077844311377245,
            "no_speech_prob": 0.0003749398747459054
        },
        {
            "id": 38,
            "seek": 5800,
            "start": 85.16,
            "end": 87.84,
            "text": " Why didn't you just do this when we hired you five years ago?",
            "tokens": [
                51722,
                1545,
                994,
                380,
                291,
                445,
                360,
                341,
                562,
                321,
                13144,
                291,
                1732,
                924,
                2057,
                30,
                51856
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17838196407090748,
            "compression_ratio": 1.6077844311377245,
            "no_speech_prob": 0.0003749398747459054
        },
        {
            "id": 39,
            "seek": 8784,
            "start": 88.64,
            "end": 90.16,
            "text": " But anyways, what's next?",
            "tokens": [
                50404,
                583,
                13448,
                11,
                437,
                311,
                958,
                30,
                50480
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1810420816594904,
            "compression_ratio": 1.2953020134228188,
            "no_speech_prob": 0.00010621341789374128
        },
        {
            "id": 40,
            "seek": 8784,
            "start": 90.16,
            "end": 92.56,
            "text": " Well, AI's getting better at persuasion,",
            "tokens": [
                50480,
                1042,
                11,
                7318,
                311,
                1242,
                1101,
                412,
                16336,
                6822,
                11,
                50600
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1810420816594904,
            "compression_ratio": 1.2953020134228188,
            "no_speech_prob": 0.00010621341789374128
        },
        {
            "id": 41,
            "seek": 8784,
            "start": 92.56,
            "end": 94.24000000000001,
            "text": " setting unrealistic goals,",
            "tokens": [
                50600,
                3287,
                42867,
                5493,
                11,
                50684
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1810420816594904,
            "compression_ratio": 1.2953020134228188,
            "no_speech_prob": 0.00010621341789374128
        },
        {
            "id": 42,
            "seek": 8784,
            "start": 94.24000000000001,
            "end": 97.64,
            "text": " and overusing jargon like synergy and circle back around.",
            "tokens": [
                50684,
                293,
                670,
                7981,
                15181,
                10660,
                411,
                50163,
                293,
                6329,
                646,
                926,
                13,
                50854
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1810420816594904,
            "compression_ratio": 1.2953020134228188,
            "no_speech_prob": 0.00010621341789374128
        },
        {
            "id": 43,
            "seek": 8784,
            "start": 97.64,
            "end": 99.64,
            "text": " So I think it's coming for your job next.",
            "tokens": [
                50854,
                407,
                286,
                519,
                309,
                311,
                1348,
                337,
                428,
                1691,
                958,
                13,
                50954
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1810420816594904,
            "compression_ratio": 1.2953020134228188,
            "no_speech_prob": 0.00010621341789374128
        }
    ],
    "language": "en",
    "filename": "2025-02-22_21-28-18_DGY-FpLyV9g.mp4",
    "account": "rajistics",
    "shortcode": "DGY-FpLyV9g",
    "timestamp": "2025-02-22T21:28:18",
    "caption": "LLMs can streamline existing AI/ML operations by replacing specialized models (e.g., BERT for classification, SpaCy for NER, T5 for summarization) with a single foundation model that handles multiple NLP tasks through prompt engineering, reducing both infrastructure complexity and maintenance overhead. The consolidation eliminates the need for task-specific data preprocessing pipelines, model retraining cycles, and separate deployment environments, while also potentially replacing costly external API services for tasks like translation and data annotation - though with the caveat that human oversight remains crucial for quality assurance and edge cases.",
    "likes": 75,
    "comments": 1,
    "url": "https://www.instagram.com/p/DGY-FpLyV9g/",
    "username": "rajistics",
    "download_date": "2025-03-11T22:21:38.511166"
}