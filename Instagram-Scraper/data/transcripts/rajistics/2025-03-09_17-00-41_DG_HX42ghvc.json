{
    "text": " I'm worried. How am I going to build a machine learning model on such a small data set? What's small for you? For this problem, I only have 100 rows of data. And when I set aside 20 for a test and 20 more for a holdout, that only leaves 60 rows of data. That doesn't seem that much. Do we have a big data project I could work on? Each of those data points cost over $5,000. We're not going to get more data easily, and this is a very valuable project for our team. Wow! My biggest concern with using machine learning is overfitting. If we had a lot of data like in this example, I wouldn't worry about overfitting. When we have only a little bit of data like in this example, there's a lot of different ways that that model could be created that might not actually generalize and capture the true pattern underneath. Oh yeah, that isn't good. Well, to get more out of your training data, you should use cross validation. Studies have shown using cross validation gets you better performance. Take a look at something like nested cross validation for what you're doing. Glad you aren't crossed with me. Go check sidekit. There's already functions built for cross validation. My suggestion is to start with simpler models. So take a look at support vector machines, Ureka, or an elastic net. I'd also suggest starting with an elastic net because of the built-in feature selection. That feature selection is going to reduce that number of features and having fewer features means less features that are likely to be susceptible to noise or spurious correlation. I remember us talking about lasso and elastic net. These are pretty common for the scenario you're in, especially when you have a lot of features and just a little bit of data. One pro-level tip I like to use is changing the random seed. By rerunning the analysis with different random seeds, you can start to separate out the signal from the noise. In this way, you might be able to, for example, identify what is the certain set or group of features that's consistent between different runs. If you find those, probably a good chance of those are going to generalize out to new data and you're not going to be just overfitting. Yikes! Isn't that going to take a long time to run? With your data set this small, I don't think trading time is going to be too big of an issue. Thanks everyone, I feel a lot better and my knowledge is a lot larger!",
    "segments": [
        {
            "id": 0,
            "seek": 0,
            "start": 0.0,
            "end": 1.0,
            "text": " I'm worried.",
            "tokens": [
                50364,
                286,
                478,
                5804,
                13,
                50414
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15705239467131785,
            "compression_ratio": 1.6521739130434783,
            "no_speech_prob": 0.023443562909960747
        },
        {
            "id": 1,
            "seek": 0,
            "start": 1.0,
            "end": 4.2,
            "text": " How am I going to build a machine learning model on such a small data set?",
            "tokens": [
                50414,
                1012,
                669,
                286,
                516,
                281,
                1322,
                257,
                3479,
                2539,
                2316,
                322,
                1270,
                257,
                1359,
                1412,
                992,
                30,
                50574
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15705239467131785,
            "compression_ratio": 1.6521739130434783,
            "no_speech_prob": 0.023443562909960747
        },
        {
            "id": 2,
            "seek": 0,
            "start": 4.2,
            "end": 5.2,
            "text": " What's small for you?",
            "tokens": [
                50574,
                708,
                311,
                1359,
                337,
                291,
                30,
                50624
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15705239467131785,
            "compression_ratio": 1.6521739130434783,
            "no_speech_prob": 0.023443562909960747
        },
        {
            "id": 3,
            "seek": 0,
            "start": 5.2,
            "end": 7.5600000000000005,
            "text": " For this problem, I only have 100 rows of data.",
            "tokens": [
                50624,
                1171,
                341,
                1154,
                11,
                286,
                787,
                362,
                2319,
                13241,
                295,
                1412,
                13,
                50742
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15705239467131785,
            "compression_ratio": 1.6521739130434783,
            "no_speech_prob": 0.023443562909960747
        },
        {
            "id": 4,
            "seek": 0,
            "start": 7.5600000000000005,
            "end": 12.280000000000001,
            "text": " And when I set aside 20 for a test and 20 more for a holdout, that only leaves 60 rows",
            "tokens": [
                50742,
                400,
                562,
                286,
                992,
                7359,
                945,
                337,
                257,
                1500,
                293,
                945,
                544,
                337,
                257,
                1797,
                346,
                11,
                300,
                787,
                5510,
                4060,
                13241,
                50978
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15705239467131785,
            "compression_ratio": 1.6521739130434783,
            "no_speech_prob": 0.023443562909960747
        },
        {
            "id": 5,
            "seek": 0,
            "start": 12.280000000000001,
            "end": 13.280000000000001,
            "text": " of data.",
            "tokens": [
                50978,
                295,
                1412,
                13,
                51028
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15705239467131785,
            "compression_ratio": 1.6521739130434783,
            "no_speech_prob": 0.023443562909960747
        },
        {
            "id": 6,
            "seek": 0,
            "start": 13.280000000000001,
            "end": 15.64,
            "text": " That doesn't seem that much.",
            "tokens": [
                51028,
                663,
                1177,
                380,
                1643,
                300,
                709,
                13,
                51146
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15705239467131785,
            "compression_ratio": 1.6521739130434783,
            "no_speech_prob": 0.023443562909960747
        },
        {
            "id": 7,
            "seek": 0,
            "start": 15.64,
            "end": 17.88,
            "text": " Do we have a big data project I could work on?",
            "tokens": [
                51146,
                1144,
                321,
                362,
                257,
                955,
                1412,
                1716,
                286,
                727,
                589,
                322,
                30,
                51258
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15705239467131785,
            "compression_ratio": 1.6521739130434783,
            "no_speech_prob": 0.023443562909960747
        },
        {
            "id": 8,
            "seek": 0,
            "start": 17.88,
            "end": 20.28,
            "text": " Each of those data points cost over $5,000.",
            "tokens": [
                51258,
                6947,
                295,
                729,
                1412,
                2793,
                2063,
                670,
                1848,
                20,
                11,
                1360,
                13,
                51378
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15705239467131785,
            "compression_ratio": 1.6521739130434783,
            "no_speech_prob": 0.023443562909960747
        },
        {
            "id": 9,
            "seek": 0,
            "start": 20.28,
            "end": 24.36,
            "text": " We're not going to get more data easily, and this is a very valuable project for our team.",
            "tokens": [
                51378,
                492,
                434,
                406,
                516,
                281,
                483,
                544,
                1412,
                3612,
                11,
                293,
                341,
                307,
                257,
                588,
                8263,
                1716,
                337,
                527,
                1469,
                13,
                51582
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15705239467131785,
            "compression_ratio": 1.6521739130434783,
            "no_speech_prob": 0.023443562909960747
        },
        {
            "id": 10,
            "seek": 0,
            "start": 24.36,
            "end": 25.36,
            "text": " Wow!",
            "tokens": [
                51582,
                3153,
                0,
                51632
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15705239467131785,
            "compression_ratio": 1.6521739130434783,
            "no_speech_prob": 0.023443562909960747
        },
        {
            "id": 11,
            "seek": 0,
            "start": 25.36,
            "end": 28.44,
            "text": " My biggest concern with using machine learning is overfitting.",
            "tokens": [
                51632,
                1222,
                3880,
                3136,
                365,
                1228,
                3479,
                2539,
                307,
                670,
                69,
                2414,
                13,
                51786
            ],
            "temperature": 0.0,
            "avg_logprob": -0.15705239467131785,
            "compression_ratio": 1.6521739130434783,
            "no_speech_prob": 0.023443562909960747
        },
        {
            "id": 12,
            "seek": 2844,
            "start": 28.44,
            "end": 32.800000000000004,
            "text": " If we had a lot of data like in this example, I wouldn't worry about overfitting.",
            "tokens": [
                50364,
                759,
                321,
                632,
                257,
                688,
                295,
                1412,
                411,
                294,
                341,
                1365,
                11,
                286,
                2759,
                380,
                3292,
                466,
                670,
                69,
                2414,
                13,
                50582
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17188081673696531,
            "compression_ratio": 1.7861635220125787,
            "no_speech_prob": 0.0023370583076030016
        },
        {
            "id": 13,
            "seek": 2844,
            "start": 32.800000000000004,
            "end": 37.74,
            "text": " When we have only a little bit of data like in this example, there's a lot of different",
            "tokens": [
                50582,
                1133,
                321,
                362,
                787,
                257,
                707,
                857,
                295,
                1412,
                411,
                294,
                341,
                1365,
                11,
                456,
                311,
                257,
                688,
                295,
                819,
                50829
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17188081673696531,
            "compression_ratio": 1.7861635220125787,
            "no_speech_prob": 0.0023370583076030016
        },
        {
            "id": 14,
            "seek": 2844,
            "start": 37.74,
            "end": 42.32,
            "text": " ways that that model could be created that might not actually generalize and capture the",
            "tokens": [
                50829,
                2098,
                300,
                300,
                2316,
                727,
                312,
                2942,
                300,
                1062,
                406,
                767,
                2674,
                1125,
                293,
                7983,
                264,
                51058
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17188081673696531,
            "compression_ratio": 1.7861635220125787,
            "no_speech_prob": 0.0023370583076030016
        },
        {
            "id": 15,
            "seek": 2844,
            "start": 42.32,
            "end": 43.64,
            "text": " true pattern underneath.",
            "tokens": [
                51058,
                2074,
                5102,
                7223,
                13,
                51124
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17188081673696531,
            "compression_ratio": 1.7861635220125787,
            "no_speech_prob": 0.0023370583076030016
        },
        {
            "id": 16,
            "seek": 2844,
            "start": 43.64,
            "end": 45.32,
            "text": " Oh yeah, that isn't good.",
            "tokens": [
                51124,
                876,
                1338,
                11,
                300,
                1943,
                380,
                665,
                13,
                51208
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17188081673696531,
            "compression_ratio": 1.7861635220125787,
            "no_speech_prob": 0.0023370583076030016
        },
        {
            "id": 17,
            "seek": 2844,
            "start": 45.32,
            "end": 49.52,
            "text": " Well, to get more out of your training data, you should use cross validation.",
            "tokens": [
                51208,
                1042,
                11,
                281,
                483,
                544,
                484,
                295,
                428,
                3097,
                1412,
                11,
                291,
                820,
                764,
                3278,
                24071,
                13,
                51418
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17188081673696531,
            "compression_ratio": 1.7861635220125787,
            "no_speech_prob": 0.0023370583076030016
        },
        {
            "id": 18,
            "seek": 2844,
            "start": 49.52,
            "end": 52.8,
            "text": " Studies have shown using cross validation gets you better performance.",
            "tokens": [
                51418,
                17515,
                362,
                4898,
                1228,
                3278,
                24071,
                2170,
                291,
                1101,
                3389,
                13,
                51582
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17188081673696531,
            "compression_ratio": 1.7861635220125787,
            "no_speech_prob": 0.0023370583076030016
        },
        {
            "id": 19,
            "seek": 2844,
            "start": 52.8,
            "end": 55.72,
            "text": " Take a look at something like nested cross validation for what you're doing.",
            "tokens": [
                51582,
                3664,
                257,
                574,
                412,
                746,
                411,
                15646,
                292,
                3278,
                24071,
                337,
                437,
                291,
                434,
                884,
                13,
                51728
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17188081673696531,
            "compression_ratio": 1.7861635220125787,
            "no_speech_prob": 0.0023370583076030016
        },
        {
            "id": 20,
            "seek": 2844,
            "start": 55.72,
            "end": 57.52,
            "text": " Glad you aren't crossed with me.",
            "tokens": [
                51728,
                28301,
                291,
                3212,
                380,
                14622,
                365,
                385,
                13,
                51818
            ],
            "temperature": 0.0,
            "avg_logprob": -0.17188081673696531,
            "compression_ratio": 1.7861635220125787,
            "no_speech_prob": 0.0023370583076030016
        },
        {
            "id": 21,
            "seek": 5752,
            "start": 57.52,
            "end": 58.52,
            "text": " Go check sidekit.",
            "tokens": [
                50364,
                1037,
                1520,
                1252,
                22681,
                13,
                50414
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22320000464174927,
            "compression_ratio": 1.7363013698630136,
            "no_speech_prob": 0.0018627116223797202
        },
        {
            "id": 22,
            "seek": 5752,
            "start": 58.52,
            "end": 60.720000000000006,
            "text": " There's already functions built for cross validation.",
            "tokens": [
                50414,
                821,
                311,
                1217,
                6828,
                3094,
                337,
                3278,
                24071,
                13,
                50524
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22320000464174927,
            "compression_ratio": 1.7363013698630136,
            "no_speech_prob": 0.0018627116223797202
        },
        {
            "id": 23,
            "seek": 5752,
            "start": 60.720000000000006,
            "end": 63.2,
            "text": " My suggestion is to start with simpler models.",
            "tokens": [
                50524,
                1222,
                16541,
                307,
                281,
                722,
                365,
                18587,
                5245,
                13,
                50648
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22320000464174927,
            "compression_ratio": 1.7363013698630136,
            "no_speech_prob": 0.0018627116223797202
        },
        {
            "id": 24,
            "seek": 5752,
            "start": 63.2,
            "end": 67.76,
            "text": " So take a look at support vector machines, Ureka, or an elastic net.",
            "tokens": [
                50648,
                407,
                747,
                257,
                574,
                412,
                1406,
                8062,
                8379,
                11,
                624,
                265,
                2330,
                11,
                420,
                364,
                17115,
                2533,
                13,
                50876
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22320000464174927,
            "compression_ratio": 1.7363013698630136,
            "no_speech_prob": 0.0018627116223797202
        },
        {
            "id": 25,
            "seek": 5752,
            "start": 67.76,
            "end": 72.4,
            "text": " I'd also suggest starting with an elastic net because of the built-in feature selection.",
            "tokens": [
                50876,
                286,
                1116,
                611,
                3402,
                2891,
                365,
                364,
                17115,
                2533,
                570,
                295,
                264,
                3094,
                12,
                259,
                4111,
                9450,
                13,
                51108
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22320000464174927,
            "compression_ratio": 1.7363013698630136,
            "no_speech_prob": 0.0018627116223797202
        },
        {
            "id": 26,
            "seek": 5752,
            "start": 72.4,
            "end": 76.72,
            "text": " That feature selection is going to reduce that number of features and having fewer features",
            "tokens": [
                51108,
                663,
                4111,
                9450,
                307,
                516,
                281,
                5407,
                300,
                1230,
                295,
                4122,
                293,
                1419,
                13366,
                4122,
                51324
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22320000464174927,
            "compression_ratio": 1.7363013698630136,
            "no_speech_prob": 0.0018627116223797202
        },
        {
            "id": 27,
            "seek": 5752,
            "start": 76.72,
            "end": 81.52000000000001,
            "text": " means less features that are likely to be susceptible to noise or spurious correlation.",
            "tokens": [
                51324,
                1355,
                1570,
                4122,
                300,
                366,
                3700,
                281,
                312,
                31249,
                281,
                5658,
                420,
                637,
                24274,
                20009,
                13,
                51564
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22320000464174927,
            "compression_ratio": 1.7363013698630136,
            "no_speech_prob": 0.0018627116223797202
        },
        {
            "id": 28,
            "seek": 5752,
            "start": 81.52000000000001,
            "end": 84.76,
            "text": " I remember us talking about lasso and elastic net.",
            "tokens": [
                51564,
                286,
                1604,
                505,
                1417,
                466,
                2439,
                539,
                293,
                17115,
                2533,
                13,
                51726
            ],
            "temperature": 0.0,
            "avg_logprob": -0.22320000464174927,
            "compression_ratio": 1.7363013698630136,
            "no_speech_prob": 0.0018627116223797202
        },
        {
            "id": 29,
            "seek": 8476,
            "start": 84.76,
            "end": 88.84,
            "text": " These are pretty common for the scenario you're in, especially when you have a lot of features",
            "tokens": [
                50364,
                1981,
                366,
                1238,
                2689,
                337,
                264,
                9005,
                291,
                434,
                294,
                11,
                2318,
                562,
                291,
                362,
                257,
                688,
                295,
                4122,
                50568
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1584813811562278,
            "compression_ratio": 1.697452229299363,
            "no_speech_prob": 0.011856994591653347
        },
        {
            "id": 30,
            "seek": 8476,
            "start": 88.84,
            "end": 90.44,
            "text": " and just a little bit of data.",
            "tokens": [
                50568,
                293,
                445,
                257,
                707,
                857,
                295,
                1412,
                13,
                50648
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1584813811562278,
            "compression_ratio": 1.697452229299363,
            "no_speech_prob": 0.011856994591653347
        },
        {
            "id": 31,
            "seek": 8476,
            "start": 90.44,
            "end": 93.96000000000001,
            "text": " One pro-level tip I like to use is changing the random seed.",
            "tokens": [
                50648,
                1485,
                447,
                12,
                12418,
                4125,
                286,
                411,
                281,
                764,
                307,
                4473,
                264,
                4974,
                8871,
                13,
                50824
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1584813811562278,
            "compression_ratio": 1.697452229299363,
            "no_speech_prob": 0.011856994591653347
        },
        {
            "id": 32,
            "seek": 8476,
            "start": 93.96000000000001,
            "end": 98.4,
            "text": " By rerunning the analysis with different random seeds, you can start to separate out the",
            "tokens": [
                50824,
                3146,
                43819,
                25589,
                264,
                5215,
                365,
                819,
                4974,
                9203,
                11,
                291,
                393,
                722,
                281,
                4994,
                484,
                264,
                51046
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1584813811562278,
            "compression_ratio": 1.697452229299363,
            "no_speech_prob": 0.011856994591653347
        },
        {
            "id": 33,
            "seek": 8476,
            "start": 98.4,
            "end": 100.84,
            "text": " signal from the noise.",
            "tokens": [
                51046,
                6358,
                490,
                264,
                5658,
                13,
                51168
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1584813811562278,
            "compression_ratio": 1.697452229299363,
            "no_speech_prob": 0.011856994591653347
        },
        {
            "id": 34,
            "seek": 8476,
            "start": 100.84,
            "end": 105.04,
            "text": " In this way, you might be able to, for example, identify what is the certain set or group",
            "tokens": [
                51168,
                682,
                341,
                636,
                11,
                291,
                1062,
                312,
                1075,
                281,
                11,
                337,
                1365,
                11,
                5876,
                437,
                307,
                264,
                1629,
                992,
                420,
                1594,
                51378
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1584813811562278,
            "compression_ratio": 1.697452229299363,
            "no_speech_prob": 0.011856994591653347
        },
        {
            "id": 35,
            "seek": 8476,
            "start": 105.04,
            "end": 108.4,
            "text": " of features that's consistent between different runs.",
            "tokens": [
                51378,
                295,
                4122,
                300,
                311,
                8398,
                1296,
                819,
                6676,
                13,
                51546
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1584813811562278,
            "compression_ratio": 1.697452229299363,
            "no_speech_prob": 0.011856994591653347
        },
        {
            "id": 36,
            "seek": 8476,
            "start": 108.4,
            "end": 113.80000000000001,
            "text": " If you find those, probably a good chance of those are going to generalize out to new data",
            "tokens": [
                51546,
                759,
                291,
                915,
                729,
                11,
                1391,
                257,
                665,
                2931,
                295,
                729,
                366,
                516,
                281,
                2674,
                1125,
                484,
                281,
                777,
                1412,
                51816
            ],
            "temperature": 0.0,
            "avg_logprob": -0.1584813811562278,
            "compression_ratio": 1.697452229299363,
            "no_speech_prob": 0.011856994591653347
        },
        {
            "id": 37,
            "seek": 11380,
            "start": 113.8,
            "end": 115.48,
            "text": " and you're not going to be just overfitting.",
            "tokens": [
                50364,
                293,
                291,
                434,
                406,
                516,
                281,
                312,
                445,
                670,
                69,
                2414,
                13,
                50448
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2465367502980418,
            "compression_ratio": 1.5263157894736843,
            "no_speech_prob": 0.058325350284576416
        },
        {
            "id": 38,
            "seek": 11380,
            "start": 115.48,
            "end": 116.48,
            "text": " Yikes!",
            "tokens": [
                50448,
                398,
                8916,
                0,
                50498
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2465367502980418,
            "compression_ratio": 1.5263157894736843,
            "no_speech_prob": 0.058325350284576416
        },
        {
            "id": 39,
            "seek": 11380,
            "start": 116.48,
            "end": 117.48,
            "text": " Isn't that going to take a long time to run?",
            "tokens": [
                50498,
                6998,
                380,
                300,
                516,
                281,
                747,
                257,
                938,
                565,
                281,
                1190,
                30,
                50548
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2465367502980418,
            "compression_ratio": 1.5263157894736843,
            "no_speech_prob": 0.058325350284576416
        },
        {
            "id": 40,
            "seek": 11380,
            "start": 117.48,
            "end": 121.39999999999999,
            "text": " With your data set this small, I don't think trading time is going to be too big of an issue.",
            "tokens": [
                50548,
                2022,
                428,
                1412,
                992,
                341,
                1359,
                11,
                286,
                500,
                380,
                519,
                9529,
                565,
                307,
                516,
                281,
                312,
                886,
                955,
                295,
                364,
                2734,
                13,
                50744
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2465367502980418,
            "compression_ratio": 1.5263157894736843,
            "no_speech_prob": 0.058325350284576416
        },
        {
            "id": 41,
            "seek": 11380,
            "start": 121.39999999999999,
            "end": 125.16,
            "text": " Thanks everyone, I feel a lot better and my knowledge is a lot larger!",
            "tokens": [
                50744,
                2561,
                1518,
                11,
                286,
                841,
                257,
                688,
                1101,
                293,
                452,
                3601,
                307,
                257,
                688,
                4833,
                0,
                50932
            ],
            "temperature": 0.0,
            "avg_logprob": -0.2465367502980418,
            "compression_ratio": 1.5263157894736843,
            "no_speech_prob": 0.058325350284576416
        }
    ],
    "language": "en",
    "filename": "2025-03-09_17-00-41_DG_HX42ghvc.mp4",
    "account": "rajistics",
    "shortcode": "DG_HX42ghvc",
    "timestamp": "2025-03-09T17:00:41",
    "caption": "Tips for working with small datasets. This includes using cross-validation, models like lasso, and running multiple iterations of feature importance with different random seeds.",
    "likes": 245,
    "comments": 2,
    "url": "https://www.instagram.com/p/DG_HX42ghvc/",
    "username": "rajistics",
    "download_date": "2025-03-11T22:20:23.762919"
}