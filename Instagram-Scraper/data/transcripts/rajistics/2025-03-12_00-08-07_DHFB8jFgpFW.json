{
    "text": " This neural network nonsense has given me a headache. Why did data scientists have to make everything so complicated? Well, you want a complex algorithm. The more complicated and fancy the algorithm is, the better it's acuers. Hold on there. We do have simpler, more explainable models. Finally, someone that gets it. A popular option is generalized additive models or GAMs. They provide a coefficient for every feature, so you can understand how the feature is affecting the prediction. GAMs? Isn't that something you put on scooms? No, but here's a rating table that shows all the different features and what the coefficient is or how much they will contribute to the prediction. Oh boy, that's way too much. A simpler approach would be generating rules for our problem. We can use decision trees to help create these rules. They say I am a bit of a rule breaker. So the more rules we add, the more accurate the model gets. But if we add too many rules, it's going to be hard to explain. So it's a trade-off game again. One of the simplest modeling approaches we can use is a scorecard like this. Kind of like how you calculate a credit rating? Now you're speaking my language. Wow, I had no idea you could use complex algorithms to actually build a simpler model. Well, I suddenly got in the mood for scones. Why don't we go grab some and I'll give you a few starting points.",
    "segments": [
        {
            "id": 0,
            "seek": 0,
            "start": 0.0,
            "end": 2.64,
            "text": " This neural network nonsense has given me a headache.",
            "tokens": [
                50364,
                639,
                18161,
                3209,
                14925,
                575,
                2212,
                385,
                257,
                23520,
                13,
                50496
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16684978148516486,
            "compression_ratio": 1.6349693251533743,
            "no_speech_prob": 0.0062641785480082035
        },
        {
            "id": 1,
            "seek": 0,
            "start": 2.64,
            "end": 5.28,
            "text": " Why did data scientists have to make everything so complicated?",
            "tokens": [
                50496,
                1545,
                630,
                1412,
                7708,
                362,
                281,
                652,
                1203,
                370,
                6179,
                30,
                50628
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16684978148516486,
            "compression_ratio": 1.6349693251533743,
            "no_speech_prob": 0.0062641785480082035
        },
        {
            "id": 2,
            "seek": 0,
            "start": 5.28,
            "end": 7.44,
            "text": " Well, you want a complex algorithm.",
            "tokens": [
                50628,
                1042,
                11,
                291,
                528,
                257,
                3997,
                9284,
                13,
                50736
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16684978148516486,
            "compression_ratio": 1.6349693251533743,
            "no_speech_prob": 0.0062641785480082035
        },
        {
            "id": 3,
            "seek": 0,
            "start": 7.44,
            "end": 11.36,
            "text": " The more complicated and fancy the algorithm is, the better it's acuers.",
            "tokens": [
                50736,
                440,
                544,
                6179,
                293,
                10247,
                264,
                9284,
                307,
                11,
                264,
                1101,
                309,
                311,
                696,
                84,
                433,
                13,
                50932
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16684978148516486,
            "compression_ratio": 1.6349693251533743,
            "no_speech_prob": 0.0062641785480082035
        },
        {
            "id": 4,
            "seek": 0,
            "start": 11.36,
            "end": 14.32,
            "text": " Hold on there. We do have simpler, more explainable models.",
            "tokens": [
                50932,
                6962,
                322,
                456,
                13,
                492,
                360,
                362,
                18587,
                11,
                544,
                2903,
                712,
                5245,
                13,
                51080
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16684978148516486,
            "compression_ratio": 1.6349693251533743,
            "no_speech_prob": 0.0062641785480082035
        },
        {
            "id": 5,
            "seek": 0,
            "start": 14.32,
            "end": 15.84,
            "text": " Finally, someone that gets it.",
            "tokens": [
                51080,
                6288,
                11,
                1580,
                300,
                2170,
                309,
                13,
                51156
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16684978148516486,
            "compression_ratio": 1.6349693251533743,
            "no_speech_prob": 0.0062641785480082035
        },
        {
            "id": 6,
            "seek": 0,
            "start": 15.84,
            "end": 19.12,
            "text": " A popular option is generalized additive models or GAMs.",
            "tokens": [
                51156,
                316,
                3743,
                3614,
                307,
                44498,
                45558,
                5245,
                420,
                460,
                2865,
                82,
                13,
                51320
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16684978148516486,
            "compression_ratio": 1.6349693251533743,
            "no_speech_prob": 0.0062641785480082035
        },
        {
            "id": 7,
            "seek": 0,
            "start": 19.12,
            "end": 21.44,
            "text": " They provide a coefficient for every feature,",
            "tokens": [
                51320,
                814,
                2893,
                257,
                17619,
                337,
                633,
                4111,
                11,
                51436
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16684978148516486,
            "compression_ratio": 1.6349693251533743,
            "no_speech_prob": 0.0062641785480082035
        },
        {
            "id": 8,
            "seek": 0,
            "start": 21.44,
            "end": 24.16,
            "text": " so you can understand how the feature is affecting the prediction.",
            "tokens": [
                51436,
                370,
                291,
                393,
                1223,
                577,
                264,
                4111,
                307,
                17476,
                264,
                17630,
                13,
                51572
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16684978148516486,
            "compression_ratio": 1.6349693251533743,
            "no_speech_prob": 0.0062641785480082035
        },
        {
            "id": 9,
            "seek": 0,
            "start": 24.16,
            "end": 26.560000000000002,
            "text": " GAMs? Isn't that something you put on scooms?",
            "tokens": [
                51572,
                460,
                2865,
                82,
                30,
                6998,
                380,
                300,
                746,
                291,
                829,
                322,
                795,
                78,
                4785,
                30,
                51692
            ],
            "temperature": 0.0,
            "avg_logprob": -0.16684978148516486,
            "compression_ratio": 1.6349693251533743,
            "no_speech_prob": 0.0062641785480082035
        },
        {
            "id": 10,
            "seek": 2656,
            "start": 26.639999999999997,
            "end": 30.16,
            "text": " No, but here's a rating table that shows all the different features",
            "tokens": [
                50368,
                883,
                11,
                457,
                510,
                311,
                257,
                10990,
                3199,
                300,
                3110,
                439,
                264,
                819,
                4122,
                50544
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07905529022216796,
            "compression_ratio": 1.7300613496932515,
            "no_speech_prob": 0.005482017062604427
        },
        {
            "id": 11,
            "seek": 2656,
            "start": 30.16,
            "end": 33.92,
            "text": " and what the coefficient is or how much they will contribute to the prediction.",
            "tokens": [
                50544,
                293,
                437,
                264,
                17619,
                307,
                420,
                577,
                709,
                436,
                486,
                10586,
                281,
                264,
                17630,
                13,
                50732
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07905529022216796,
            "compression_ratio": 1.7300613496932515,
            "no_speech_prob": 0.005482017062604427
        },
        {
            "id": 12,
            "seek": 2656,
            "start": 33.92,
            "end": 35.519999999999996,
            "text": " Oh boy, that's way too much.",
            "tokens": [
                50732,
                876,
                3237,
                11,
                300,
                311,
                636,
                886,
                709,
                13,
                50812
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07905529022216796,
            "compression_ratio": 1.7300613496932515,
            "no_speech_prob": 0.005482017062604427
        },
        {
            "id": 13,
            "seek": 2656,
            "start": 35.519999999999996,
            "end": 38.48,
            "text": " A simpler approach would be generating rules for our problem.",
            "tokens": [
                50812,
                316,
                18587,
                3109,
                576,
                312,
                17746,
                4474,
                337,
                527,
                1154,
                13,
                50960
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07905529022216796,
            "compression_ratio": 1.7300613496932515,
            "no_speech_prob": 0.005482017062604427
        },
        {
            "id": 14,
            "seek": 2656,
            "start": 38.48,
            "end": 41.36,
            "text": " We can use decision trees to help create these rules.",
            "tokens": [
                50960,
                492,
                393,
                764,
                3537,
                5852,
                281,
                854,
                1884,
                613,
                4474,
                13,
                51104
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07905529022216796,
            "compression_ratio": 1.7300613496932515,
            "no_speech_prob": 0.005482017062604427
        },
        {
            "id": 15,
            "seek": 2656,
            "start": 41.36,
            "end": 43.76,
            "text": " They say I am a bit of a rule breaker.",
            "tokens": [
                51104,
                814,
                584,
                286,
                669,
                257,
                857,
                295,
                257,
                4978,
                35375,
                13,
                51224
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07905529022216796,
            "compression_ratio": 1.7300613496932515,
            "no_speech_prob": 0.005482017062604427
        },
        {
            "id": 16,
            "seek": 2656,
            "start": 43.76,
            "end": 47.12,
            "text": " So the more rules we add, the more accurate the model gets.",
            "tokens": [
                51224,
                407,
                264,
                544,
                4474,
                321,
                909,
                11,
                264,
                544,
                8559,
                264,
                2316,
                2170,
                13,
                51392
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07905529022216796,
            "compression_ratio": 1.7300613496932515,
            "no_speech_prob": 0.005482017062604427
        },
        {
            "id": 17,
            "seek": 2656,
            "start": 47.12,
            "end": 49.92,
            "text": " But if we add too many rules, it's going to be hard to explain.",
            "tokens": [
                51392,
                583,
                498,
                321,
                909,
                886,
                867,
                4474,
                11,
                309,
                311,
                516,
                281,
                312,
                1152,
                281,
                2903,
                13,
                51532
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07905529022216796,
            "compression_ratio": 1.7300613496932515,
            "no_speech_prob": 0.005482017062604427
        },
        {
            "id": 18,
            "seek": 2656,
            "start": 49.92,
            "end": 51.28,
            "text": " So it's a trade-off game again.",
            "tokens": [
                51532,
                407,
                309,
                311,
                257,
                4923,
                12,
                4506,
                1216,
                797,
                13,
                51600
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07905529022216796,
            "compression_ratio": 1.7300613496932515,
            "no_speech_prob": 0.005482017062604427
        },
        {
            "id": 19,
            "seek": 2656,
            "start": 51.28,
            "end": 54.96,
            "text": " One of the simplest modeling approaches we can use is a scorecard like this.",
            "tokens": [
                51600,
                1485,
                295,
                264,
                22811,
                15983,
                11587,
                321,
                393,
                764,
                307,
                257,
                6175,
                22259,
                411,
                341,
                13,
                51784
            ],
            "temperature": 0.0,
            "avg_logprob": -0.07905529022216796,
            "compression_ratio": 1.7300613496932515,
            "no_speech_prob": 0.005482017062604427
        },
        {
            "id": 20,
            "seek": 5496,
            "start": 55.04,
            "end": 57.28,
            "text": " Kind of like how you calculate a credit rating?",
            "tokens": [
                50368,
                9242,
                295,
                411,
                577,
                291,
                8873,
                257,
                5397,
                10990,
                30,
                50480
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13630632920698685,
            "compression_ratio": 1.4307692307692308,
            "no_speech_prob": 0.0010698104742914438
        },
        {
            "id": 21,
            "seek": 5496,
            "start": 57.28,
            "end": 58.88,
            "text": " Now you're speaking my language.",
            "tokens": [
                50480,
                823,
                291,
                434,
                4124,
                452,
                2856,
                13,
                50560
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13630632920698685,
            "compression_ratio": 1.4307692307692308,
            "no_speech_prob": 0.0010698104742914438
        },
        {
            "id": 22,
            "seek": 5496,
            "start": 58.88,
            "end": 61.92,
            "text": " Wow, I had no idea you could use complex algorithms",
            "tokens": [
                50560,
                3153,
                11,
                286,
                632,
                572,
                1558,
                291,
                727,
                764,
                3997,
                14642,
                50712
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13630632920698685,
            "compression_ratio": 1.4307692307692308,
            "no_speech_prob": 0.0010698104742914438
        },
        {
            "id": 23,
            "seek": 5496,
            "start": 61.92,
            "end": 63.92,
            "text": " to actually build a simpler model.",
            "tokens": [
                50712,
                281,
                767,
                1322,
                257,
                18587,
                2316,
                13,
                50812
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13630632920698685,
            "compression_ratio": 1.4307692307692308,
            "no_speech_prob": 0.0010698104742914438
        },
        {
            "id": 24,
            "seek": 5496,
            "start": 63.92,
            "end": 65.76,
            "text": " Well, I suddenly got in the mood for scones.",
            "tokens": [
                50812,
                1042,
                11,
                286,
                5800,
                658,
                294,
                264,
                9268,
                337,
                795,
                2213,
                13,
                50904
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13630632920698685,
            "compression_ratio": 1.4307692307692308,
            "no_speech_prob": 0.0010698104742914438
        },
        {
            "id": 25,
            "seek": 5496,
            "start": 65.76,
            "end": 68.56,
            "text": " Why don't we go grab some and I'll give you a few starting points.",
            "tokens": [
                50904,
                1545,
                500,
                380,
                321,
                352,
                4444,
                512,
                293,
                286,
                603,
                976,
                291,
                257,
                1326,
                2891,
                2793,
                13,
                51044
            ],
            "temperature": 0.0,
            "avg_logprob": -0.13630632920698685,
            "compression_ratio": 1.4307692307692308,
            "no_speech_prob": 0.0010698104742914438
        }
    ],
    "language": "en",
    "filename": "2025-03-12_00-08-07_DHFB8jFgpFW.mp4",
    "account": "rajistics",
    "shortcode": "DHFB8jFgpFW",
    "timestamp": "2025-03-12T00:08:07",
    "caption": "The video contrasts complex neural networks with simpler, interpretable models like Generalized Additive Models (GAMs), which provide clear coefficients showing each feature’s impact on predictions. Rule-based approaches derived from decision trees offer another interpretable option, though they present a trade-off between accuracy and explainability. Scorecards are highlighted as one of the simplest modeling approaches, demonstrating how complex algorithms can sometimes be used to build more interpretable solutions.",
    "likes": 55,
    "comments": 0,
    "url": "https://www.instagram.com/p/DHFB8jFgpFW/",
    "username": "rajistics",
    "download_date": "2025-03-11T22:20:09.653770"
}